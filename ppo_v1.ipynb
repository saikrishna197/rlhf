{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6606979,"sourceType":"datasetVersion","datasetId":3812010}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers torch trl pandas numpy","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:08:53.459960Z","iopub.execute_input":"2023-10-23T07:08:53.460271Z","iopub.status.idle":"2023-10-23T07:09:08.886665Z","shell.execute_reply.started":"2023-10-23T07:08:53.460235Z","shell.execute_reply":"2023-10-23T07:09:08.885700Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nCollecting trl\n  Downloading trl-0.7.2-py3-none-any.whl (124 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.0/124.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl) (0.22.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl) (2.1.0)\nCollecting tyro>=0.5.7 (from trl)\n  Downloading tyro-0.5.10-py3-none-any.whl (94 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.7->trl) (0.15)\nRequirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.7->trl) (13.4.2)\nCollecting shtab>=1.5.6 (from tyro>=0.5.7->trl)\n  Downloading shtab-1.6.4-py3-none-any.whl (13 kB)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl) (5.9.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.3.7)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.70.15)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->trl) (0.18.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl) (1.3.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.7->trl) (2.2.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.7->trl) (2.15.1)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.7->trl) (0.1.0)\nInstalling collected packages: shtab, tyro, trl\nSuccessfully installed shtab-1.6.4 trl-0.7.2 tyro-0.5.10\n","output_type":"stream"}]},{"cell_type":"code","source":"import random\n\nimport numpy as np\nimport torch\nimport pandas as pd\n\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    Trainer,\n    TrainingArguments,\n    default_data_collator,\n)\n\n\ndef set_seed(seed_val=42):\n    random.seed(seed_val)\n    np.random.seed(seed_val)\n    torch.manual_seed(seed_val)\n    torch.cuda.manual_seed_all(seed_val)\n\n\n\noutput_dir = \"supervised-summarize-checkpoint\"\ntrain_batch_size = 16\ngradient_accumulation_steps = 1\nlearning_rate = 1e-5\neval_batch_size = 1\neval_steps = 500\nmax_input_length = 550\nsave_steps = 1000\nnum_train_epochs = 20\nrandom.seed(42)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:08.888547Z","iopub.execute_input":"2023-10-23T07:09:08.888851Z","iopub.status.idle":"2023-10-23T07:09:31.380959Z","shell.execute_reply.started":"2023-10-23T07:09:08.888820Z","shell.execute_reply":"2023-10-23T07:09:31.380166Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_parquet(\"/kaggle/input/data-model-files/test_policy.parquet\")","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:31.382067Z","iopub.execute_input":"2023-10-23T07:09:31.382678Z","iopub.status.idle":"2023-10-23T07:09:31.737468Z","shell.execute_reply.started":"2023-10-23T07:09:31.382649Z","shell.execute_reply":"2023-10-23T07:09:31.736545Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.iloc[12]","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:31.739974Z","iopub.execute_input":"2023-10-23T07:09:31.740371Z","iopub.status.idle":"2023-10-23T07:09:31.750448Z","shell.execute_reply.started":"2023-10-23T07:09:31.740337Z","shell.execute_reply":"2023-10-23T07:09:31.749550Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"prompt    SUBREDDIT: r/tifu\\nTITLE: TIFU bY brushing wit...\nlabel     Brush Teeth with Baking Soda without research,...\nName: 12, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"import json\n\nimport pandas as pd\nimport torch\nfrom datasets import load_dataset\nfrom torch.utils.data import Dataset\n\n\nclass TLDRDataset(Dataset):\n    def __init__(self, train_path, tokenizer, split, max_length=256):\n        self.post_list = []\n        dataset = pd.read_parquet(train_path)\n        self.labels = []\n#         dataset = dataset[:100]\n        for sample in dataset.iterrows():\n            self.post_list.append(sample[1][\"prompt\"])\n            self.labels.append(sample[1][\"label\"])\n\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        self.input_ids = []\n        self.attn_masks = []\n\n    def __len__(self):\n        return len(self.post_list)\n\n    def __getitem__(self, idx):\n        txt = self.post_list[idx]\n        label = self.labels[idx]\n\n        encodings_dict = self.tokenizer(txt, truncation=True, max_length=self.max_length, padding=\"max_length\")\n        encodings_dict_label = self.tokenizer(label,truncation=True, max_length=self.max_length, padding=\"max_length\")\n        input_ids = torch.tensor(encodings_dict[\"input_ids\"])\n        attn_masks = torch.tensor(encodings_dict[\"attention_mask\"])\n        labels_ids = torch.tensor(encodings_dict_label[\"input_ids\"])\n        return {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attn_masks,\n            \"labels\": labels_ids,\n        }\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:31.751616Z","iopub.execute_input":"2023-10-23T07:09:31.751980Z","iopub.status.idle":"2023-10-23T07:09:31.764842Z","shell.execute_reply.started":"2023-10-23T07:09:31.751949Z","shell.execute_reply":"2023-10-23T07:09:31.763670Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bigcode/tiny_starcoder_py\")\nmodel = AutoModelForCausalLM.from_pretrained(\"bigcode/tiny_starcoder_py\", use_cache=False)\ntokenizer.pad_token = tokenizer.eos_token\nmodel.resize_token_embeddings(len(tokenizer))\ntokenizer.pad_token_id = tokenizer.eos_token_id\nmodel.config.end_token_id = tokenizer.eos_token_id\nmodel.config.pad_token_id = model.config.eos_token_id","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:31.766428Z","iopub.execute_input":"2023-10-23T07:09:31.766753Z","iopub.status.idle":"2023-10-23T07:09:58.945476Z","shell.execute_reply.started":"2023-10-23T07:09:31.766723Z","shell.execute_reply":"2023-10-23T07:09:58.944544Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac1d97b518ce40a0804f906dab93a4bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/777k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6482423b846a42a1a2deea4bf46b572d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/442k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8701d89635c94a8fb845396ef31c0d0c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.06M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e1fdf3d45b4bb9be59a0e879448c39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/532 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6346e29faf0c41ae90b8fb1959c7ee61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.03k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3a9e6c5ceff4dd6883315c63afe283b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/657M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c5ec481122747ada9049e586ba6ffc7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e684fba8cb1f4bb0ba62c0b3f6007a84"}},"metadata":{}},{"name":"stderr","text":"You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 49152. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set up the datasets\ndata_path = \"/kaggle/input/data-model-files/test_policy.parquet\"\ntrain_dataset = TLDRDataset(\n    data_path,\n    tokenizer,\n    \"train\",\n    max_length=256,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:58.946869Z","iopub.execute_input":"2023-10-23T07:09:58.947542Z","iopub.status.idle":"2023-10-23T07:09:59.414085Z","shell.execute_reply.started":"2023-10-23T07:09:58.947481Z","shell.execute_reply":"2023-10-23T07:09:59.413266Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"for i in train_dataset:\n    print(i[\"input_ids\"], i[\"labels\"])\n    break","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:59.415301Z","iopub.execute_input":"2023-10-23T07:09:59.415680Z","iopub.status.idle":"2023-10-23T07:09:59.455195Z","shell.execute_reply.started":"2023-10-23T07:09:59.415645Z","shell.execute_reply":"2023-10-23T07:09:59.454328Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"tensor([ 7100,   613,  2918,   780,    44,   540,    33, 40186,   203, 13777,\n           44,  3110,   428,    35,    43,   506,    79,   623,  1672, 11970,\n          428,    35,    43,   488,   614,   646,  3654,   415,   439,  1631,\n         1159, 16661,  1246,  6366,   973,  3425,    32,   203,  3705,    44,\n        12000, 17964,  3638,  1548,    32,   439,  9845,   458,  7735,  1330,\n         5133, 31695,   432,   312,  7000,   372,  7660,   544,  2442,    30,\n         1273,   439,  4763,  2583, 42289,   312,  3493,   963,   432,  1672,\n         7713,  1412,   561, 12767,   372,   458, 18734,   308,    59,  4763,\n         5054,  1755,  1591, 12112,  2670,    30,   461,   436,  5075, 17510,\n           30,   561,  1597,   963,   432,   322, 48385,   547,   203,   203,\n         7558,   395,    19,  2770,    30,   312, 17142,   432, 22599, 14818,\n           30,   439,  7307, 29220,   372,   458,  3932,   107,   544, 18660,\n           30,  3919,   312,  9525,  2350,   688,   996,  4528,  4335,  1742,\n          432,    32,   439, 10889,   938,  1597,  3844,   432,   281,  1142,\n           30,  1259,   439,  4618, 10320,   312,  9396,  2258,   372, 12440,\n           30,  5774,    30,  5774,    32,  2688,  4484,  4335,  8872, 16512,\n          821,   322,  2432, 19076,    30,  1259,   439, 39271,   688,   996,\n         3065, 23840, 18450,   328,  4916,  5049,   996,  4335, 13639,   544,\n           31, 16033,   352,    32,  2770,    30,   996,  4142,    30,   461,\n          996,   420,  3280,   963,  8762, 19465,    30,  2258,   619, 22523,\n           32,   203,   203,  7558,   395,    32,  2770,    30,  8989,   438,\n         6783, 10191,  4487,    32,  2688, 12440,  2288, 18660,   461, 46438,\n         6172,    30, 17013,    32,  2770,    30,   358, 30288, 19212,    30,\n          439,  1597,  2258,   420,  7398,   963,   623,  7024,   461,  6186,\n          432,  3998,   323, 12837,    30,  1412,   439,  5424,   312, 46438,\n         6172,   645, 10320, 24240,  2769,   439]) tensor([   59,  6394,  2124,   458,  3932,   107,    30,  1273,  2685,  7696,\n        27082,   623, 10320,  2685,  1755, 44470, 10320,   436,   312,  5029,\n        25585,  7918,   432,  1133,    30,   439,  3860, 22958, 14051,   688,\n          439,  1631,  1159, 17090,  1441,  1672,   663,  3151,   432,   312,\n        12112,   623, 10320,    32,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0])\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\n\nprint(torch.cuda.is_available())\nprint(torch.cuda.device_count())\nprint(torch.cuda.current_device())\n","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:59.456396Z","iopub.execute_input":"2023-10-23T07:09:59.456743Z","iopub.status.idle":"2023-10-23T07:09:59.528329Z","shell.execute_reply.started":"2023-10-23T07:09:59.456713Z","shell.execute_reply":"2023-10-23T07:09:59.527335Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"True\n2\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Prepare the trainer and start training\ntraining_args = TrainingArguments(\n    output_dir=output_dir,\n    learning_rate=learning_rate,\n    per_device_train_batch_size=train_batch_size,\n#     per_device_eval_batch_size=eval_batch_size,\n    fp16=False,\n    gradient_accumulation_steps=gradient_accumulation_steps,\n    num_train_epochs=2,\n    warmup_steps=100,\n    logging_steps=10,\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:59.531269Z","iopub.execute_input":"2023-10-23T07:09:59.531570Z","iopub.status.idle":"2023-10-23T07:09:59.555675Z","shell.execute_reply.started":"2023-10-23T07:09:59.531541Z","shell.execute_reply":"2023-10-23T07:09:59.554862Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"training_args.device.index\n# b63419aefda918e85878c10764b3510f470692d5","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:59.556844Z","iopub.execute_input":"2023-10-23T07:09:59.557142Z","iopub.status.idle":"2023-10-23T07:09:59.566686Z","shell.execute_reply.started":"2023-10-23T07:09:59.557118Z","shell.execute_reply":"2023-10-23T07:09:59.565862Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n#     compute_metrics=compute_metrics,\n#     data_collator=default_data_collator,\n#     preprocess_logits_for_metrics=preprocess_logits_for_metrics\n)\ntrainer.train()\n# trainer.save_model(output_dir)","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:09:59.567643Z","iopub.execute_input":"2023-10-23T07:09:59.567878Z","iopub.status.idle":"2023-10-23T07:22:26.049416Z","shell.execute_reply.started":"2023-10-23T07:09:59.567858Z","shell.execute_reply":"2023-10-23T07:22:26.048233Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231023_071025-kblr7u9y</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/great_gatsby07/huggingface/runs/kblr7u9y' target=\"_blank\">ethereal-water-17</a></strong> to <a href='https://wandb.ai/great_gatsby07/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/great_gatsby07/huggingface' target=\"_blank\">https://wandb.ai/great_gatsby07/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/great_gatsby07/huggingface/runs/kblr7u9y' target=\"_blank\">https://wandb.ai/great_gatsby07/huggingface/runs/kblr7u9y</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='410' max='410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [410/410 11:20, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>10.188800</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>6.536500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.513900</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.478500</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.186200</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>1.063200</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.016500</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.006000</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.993700</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>1.005500</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>1.012500</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.973600</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.983300</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.969400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.977500</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.976800</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.968200</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.990100</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.963400</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.977600</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.991300</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.970200</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.962500</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.948600</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.968000</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.983000</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.953200</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.956800</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.946700</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.948600</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.961300</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.950400</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.963600</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.952700</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.968100</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.929600</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.962300</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.947800</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.953300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.931900</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.950600</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=410, training_loss=1.3873600052624213, metrics={'train_runtime': 738.1286, 'train_samples_per_second': 17.756, 'train_steps_per_second': 0.555, 'total_flos': 2417790236491776.0, 'train_loss': 1.3873600052624213, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"summarization_policy_new/\")","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:26.050741Z","iopub.execute_input":"2023-10-23T07:22:26.051130Z","iopub.status.idle":"2023-10-23T07:22:27.000125Z","shell.execute_reply.started":"2023-10-23T07:22:26.051093Z","shell.execute_reply":"2023-10-23T07:22:26.999075Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"df.iloc[0][\"label\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:27.001381Z","iopub.execute_input":"2023-10-23T07:22:27.002199Z","iopub.status.idle":"2023-10-23T07:22:27.008762Z","shell.execute_reply.started":"2023-10-23T07:22:27.002170Z","shell.execute_reply":"2023-10-23T07:22:27.007842Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'I really like this guy, but after having sex with him after only knowing him for a very brief period of time, I am worried that I may have ruined my chances of a relationship with him.'"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer\nfrom transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\"summarization_policy_new/\")\nmodel_path = \"bigcode/tiny_starcoder_py\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_path, truncation=True, max_length=256, padding=\"max_length\")\ntext = df.iloc[2][\"prompt\"]\ntokenized_text = tokenizer(text, return_tensors=\"pt\", max_length=256)","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:27.010132Z","iopub.execute_input":"2023-10-23T07:22:27.010767Z","iopub.status.idle":"2023-10-23T07:22:29.611946Z","shell.execute_reply.started":"2023-10-23T07:22:27.010742Z","shell.execute_reply":"2023-10-23T07:22:29.610952Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.decode(model.generate(**tokenized_text)[0])","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:29.613545Z","iopub.execute_input":"2023-10-23T07:22:29.613956Z","iopub.status.idle":"2023-10-23T07:22:30.272293Z","shell.execute_reply.started":"2023-10-23T07:22:29.613914Z","shell.execute_reply":"2023-10-23T07:22:30.271069Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1260: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1268: UserWarning: Input length of input_ids is 203, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"\"SUBREDDIT: r/relationships\\nTITLE: The girl [26 F] I [22 M] have been seeing for a month didn't respond to me at all yesterday while hanging out with a friend [~30? M].\\nPOST: She gets terrible service while at her house, but I texted her 3 times yesterday, 4-5 hours apart. She didn't call me until early this morning and left a voicemail that she was busy all day with a friend who showed up out of the blue.\\n\\nI saw that she posted a picture of the two of them out of her dead zone house on facebook before I texted her the last time.\\n\\nI don't mind that she hangs out with friends, and I know it's pretty early in the relationship, but am I wrong to be a little annoyed that she didn't respond until 24 hours after my first text?\\nTL;DR: <|endoftext|>\""},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reward","metadata":{}},{"cell_type":"code","source":"import torch\nimport transformers\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\nfrom trl import RewardTrainer, SFTTrainer\nfrom datasets import Dataset\nimport json\nimport pandas as pd\nfrom transformers import Trainer, TrainingArguments\n","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:36.628298Z","iopub.execute_input":"2023-10-23T07:22:36.628943Z","iopub.status.idle":"2023-10-23T07:22:39.454013Z","shell.execute_reply.started":"2023-10-23T07:22:36.628909Z","shell.execute_reply":"2023-10-23T07:22:39.452926Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"##model path\nMODEL_PATH = \"bigcode/tiny_starcoder_py\"\nDATA_PATH = \"/kaggle/input/data-model-files/test_reward.parquet\"","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:40.622437Z","iopub.execute_input":"2023-10-23T07:22:40.623178Z","iopub.status.idle":"2023-10-23T07:22:40.629152Z","shell.execute_reply.started":"2023-10-23T07:22:40.623148Z","shell.execute_reply":"2023-10-23T07:22:40.627945Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"df = pd.read_parquet(DATA_PATH)\ndf = df[:10]\nraw_dataset = Dataset.from_pandas(df)\nraw_dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:41.528099Z","iopub.execute_input":"2023-10-23T07:22:41.528453Z","iopub.status.idle":"2023-10-23T07:22:42.085467Z","shell.execute_reply.started":"2023-10-23T07:22:41.528426Z","shell.execute_reply":"2023-10-23T07:22:42.084368Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'chosen', 'rejected'],\n    num_rows: 10\n})"},"metadata":{}}]},{"cell_type":"code","source":"##defininig the model and tokenizer\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:42.201201Z","iopub.execute_input":"2023-10-23T07:22:42.201488Z","iopub.status.idle":"2023-10-23T07:22:44.604571Z","shell.execute_reply.started":"2023-10-23T07:22:42.201463Z","shell.execute_reply":"2023-10-23T07:22:44.603475Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"tokenizer.add_special_tokens({'pad_token': '[PAD]'})\ndef formatting_func(examples):\n    kwargs = {\"padding\": \"max_length\",\n              \"truncation\": True,\n              \"max_length\": 256,\n              \"return_tensors\": \"pt\"\n              }\n\n    # Prepend the prompt and a line break to the original_response and response-1 fields.\n    prompt_plus_chosen_response = examples[\"prompt\"] + \"\\n\" + examples[\"chosen\"]\n    prompt_plus_rejected_response = examples[\"prompt\"] + \"\\n\" + examples[\"rejected\"]\n\n    # Then tokenize these modified fields.\n    tokens_chosen = tokenizer.encode_plus(prompt_plus_chosen_response, **kwargs)\n    tokens_rejected = tokenizer.encode_plus(prompt_plus_rejected_response, **kwargs)\n\n    return {\n        \"input_ids_chosen\": tokens_chosen[\"input_ids\"][0], \"attention_mask_chosen\": tokens_chosen[\"attention_mask\"][0],\n        \"input_ids_rejected\": tokens_rejected[\"input_ids\"][0], \"attention_mask_rejected\": tokens_rejected[\"attention_mask\"][0]\n    }","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:44.606608Z","iopub.execute_input":"2023-10-23T07:22:44.606970Z","iopub.status.idle":"2023-10-23T07:22:44.615003Z","shell.execute_reply.started":"2023-10-23T07:22:44.606935Z","shell.execute_reply":"2023-10-23T07:22:44.614144Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"formatted_dataset = raw_dataset.map(formatting_func)\nformatted_dataset = formatted_dataset.train_test_split()","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:44.616557Z","iopub.execute_input":"2023-10-23T07:22:44.616844Z","iopub.status.idle":"2023-10-23T07:22:44.726914Z","shell.execute_reply.started":"2023-10-23T07:22:44.616819Z","shell.execute_reply":"2023-10-23T07:22:44.725953Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/10 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da7fcf5956814fa28d123230a788962e"}},"metadata":{}}]},{"cell_type":"code","source":"model.config","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:44.729399Z","iopub.execute_input":"2023-10-23T07:22:44.730171Z","iopub.status.idle":"2023-10-23T07:22:44.740298Z","shell.execute_reply.started":"2023-10-23T07:22:44.730132Z","shell.execute_reply":"2023-10-23T07:22:44.739365Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"GPTBigCodeConfig {\n  \"_name_or_path\": \"bigcode/tiny_starcoder_py\",\n  \"activation_function\": \"gelu_pytorch_tanh\",\n  \"architectures\": [\n    \"GPTBigCodeForCausalLM\"\n  ],\n  \"attention_softmax_in_fp32\": true,\n  \"attn_pdrop\": 0.1,\n  \"bos_token_id\": 0,\n  \"embd_pdrop\": 0.1,\n  \"eos_token_id\": 0,\n  \"inference_runner\": 0,\n  \"initializer_range\": 0.02,\n  \"layer_norm_epsilon\": 1e-05,\n  \"max_batch_size\": null,\n  \"max_sequence_length\": null,\n  \"model_type\": \"gpt_bigcode\",\n  \"multi_query\": true,\n  \"n_embd\": 768,\n  \"n_head\": 12,\n  \"n_inner\": 3072,\n  \"n_layer\": 20,\n  \"n_positions\": 8192,\n  \"pad_key_length\": true,\n  \"pre_allocate_kv_cache\": false,\n  \"resid_pdrop\": 0.1,\n  \"scale_attention_softmax_in_fp32\": true,\n  \"scale_attn_weights\": true,\n  \"summary_activation\": null,\n  \"summary_first_dropout\": 0.1,\n  \"summary_proj_to_labels\": true,\n  \"summary_type\": \"cls_index\",\n  \"summary_use_proj\": true,\n  \"torch_dtype\": \"float32\",\n  \"transformers_version\": \"4.33.0\",\n  \"use_cache\": true,\n  \"validate_runner_input\": true,\n  \"vocab_size\": 49152\n}"},"metadata":{}}]},{"cell_type":"code","source":"### Loading the TRL reward trainer and training the trainer\ntraining_args = TrainingArguments(\n        output_dir=\"rm_checkpoint/\",\n        num_train_epochs=1,\n        logging_steps=10,\n        gradient_accumulation_steps=1,\n        save_strategy=\"steps\",\n        evaluation_strategy=\"steps\",\n        per_device_train_batch_size=2,\n        per_device_eval_batch_size=1,\n        eval_accumulation_steps=1,\n        eval_steps=500,\n        save_steps=500,\n        warmup_steps=100,\n        logging_dir=\"./logs\",\n        learning_rate=1e-5,\n        save_total_limit=1,\n        no_cuda=False\n    )","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:44.742035Z","iopub.execute_input":"2023-10-23T07:22:44.742429Z","iopub.status.idle":"2023-10-23T07:22:44.753975Z","shell.execute_reply.started":"2023-10-23T07:22:44.742394Z","shell.execute_reply":"2023-10-23T07:22:44.752935Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"trainer = RewardTrainer(model=model,\n                        tokenizer=tokenizer,\n                        train_dataset=formatted_dataset['train'],\n                        eval_dataset=formatted_dataset['test'],\n                        args= training_args\n                        )\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:45.552714Z","iopub.execute_input":"2023-10-23T07:22:45.553079Z","iopub.status.idle":"2023-10-23T07:22:47.988862Z","shell.execute_reply.started":"2023-10-23T07:22:45.553051Z","shell.execute_reply":"2023-10-23T07:22:47.987910Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/reward_trainer.py:105: FutureWarning: Using `transformers.TrainingArguments` for `args` is deprecated and will be removed in a future version. Please use `RewardConfig` instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/reward_trainer.py:150: UserWarning: When using RewardDataCollatorWithPadding, you should set `max_length` in RewardConfig. It will be set to `512` by default, but you should do it yourself in the future.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/trl/trainer/reward_trainer.py:175: UserWarning: When using RewardDataCollatorWithPadding, you should set `remove_unused_columns=False` in your RewardConfig we have set it for you, but you should do it yourself in the future.\n  warnings.warn(\nYou're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2436: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n  warnings.warn(\nCould not estimate the number of tokens of the input, floating-point operations will not be computed\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2/2 00:00, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=2, training_loss=0.7642489075660706, metrics={'train_runtime': 1.533, 'train_samples_per_second': 4.566, 'train_steps_per_second': 1.305, 'total_flos': 0.0, 'train_loss': 0.7642489075660706, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model(\"rm_model/\")","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:47.990507Z","iopub.execute_input":"2023-10-23T07:22:47.990792Z","iopub.status.idle":"2023-10-23T07:22:49.024434Z","shell.execute_reply.started":"2023-10-23T07:22:47.990766Z","shell.execute_reply":"2023-10-23T07:22:49.023390Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"## inference the model\ndevice = \"cuda:0\"\ntokenizer = AutoTokenizer.from_pretrained(\"bigcode/tiny_starcoder_py\")\nrm_model = AutoModelForCausalLM.from_pretrained(\"rm_model/\")\nrm_model.to(device)\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\ntokenizer.pad_token = tokenizer.eos_token\n","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:49.025969Z","iopub.execute_input":"2023-10-23T07:22:49.026387Z","iopub.status.idle":"2023-10-23T07:22:51.463430Z","shell.execute_reply.started":"2023-10-23T07:22:49.026347Z","shell.execute_reply":"2023-10-23T07:22:51.462201Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def get_score(model, tokenizer, prompt, response):\n    device = \"cuda:0\"\n    instructions = tokenizer.encode_plus(prompt,\n                                       response,\n                                       padding=\"max_length\",\n                                       max_length=256,\n                                       return_tensors=\"pt\",\n                                        truncation=True).to(device)\n    with torch.no_grad():\n        outputs = model(**instructions)\n\n    logits = outputs[0]\n\n    return logits\n","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:51.465874Z","iopub.execute_input":"2023-10-23T07:22:51.466194Z","iopub.status.idle":"2023-10-23T07:22:51.474223Z","shell.execute_reply.started":"2023-10-23T07:22:51.466168Z","shell.execute_reply":"2023-10-23T07:22:51.473119Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# usage with prompt\nprompt = df.iloc[0][\"prompt\"]\nexample_prefered_response = df.iloc[0][\"chosen\"]\nexample_unprefered_response = df.iloc[0][\"rejected\"]","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:51.475749Z","iopub.execute_input":"2023-10-23T07:22:51.476194Z","iopub.status.idle":"2023-10-23T07:22:51.486904Z","shell.execute_reply.started":"2023-10-23T07:22:51.476154Z","shell.execute_reply":"2023-10-23T07:22:51.485878Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"loss1 = get_score(model, tokenizer, prompt, example_prefered_response)\nloss2= get_score(model, tokenizer, prompt, example_unprefered_response)","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:51.488113Z","iopub.execute_input":"2023-10-23T07:22:51.488964Z","iopub.status.idle":"2023-10-23T07:22:51.559733Z","shell.execute_reply.started":"2023-10-23T07:22:51.488925Z","shell.execute_reply":"2023-10-23T07:22:51.558863Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"from torch import nn\nloss = -nn.functional.logsigmoid(loss1 - loss2).mean()","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:51.561045Z","iopub.execute_input":"2023-10-23T07:22:51.561648Z","iopub.status.idle":"2023-10-23T07:22:51.567273Z","shell.execute_reply.started":"2023-10-23T07:22:51.561615Z","shell.execute_reply":"2023-10-23T07:22:51.566303Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(torch.max(loss1, axis=-1).indices[0])","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:51.568623Z","iopub.execute_input":"2023-10-23T07:22:51.568987Z","iopub.status.idle":"2023-10-23T07:22:51.590322Z","shell.execute_reply.started":"2023-10-23T07:22:51.568955Z","shell.execute_reply":"2023-10-23T07:22:51.589251Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"'_DD__\\n       \"r/\\n: Relationship RelationshipRelationship0]0ARCH\\nlsriend\\n2//M]\\n [ [ [ [ his was to the gir\\n a friends\\n\\n\\n:\\n [lfriend [ my have a aull with my19 minutes ago\\n\\n\"\"\"1 updated:** girlfriend was through my Facebook..** I my my Facebook..** my  of lf.\\n\\n** was ading for my new personirl** was was to getellpping my my my last** but I was a in\\n\\n** have ali ** of to,  tolirt me me girirl. and she had working about me.. the few of gir.1viously). was\\'t find that was it\\n\\n** was it about  twoirl and the was the Facebook, the  and she birthdayin historyirl) was in March,\\n to, f that were flited, I my g.. f-ing on her.\\n girl wass; I1 [irllfriend, 19 months. to my Facebook.. my permission. I them messages. her.lirty with her coupleirl.\\n found my with me after I through more with\\n'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ppo","metadata":{}},{"cell_type":"code","source":"import torch\nimport transformers\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\nfrom trl import RewardTrainer, SFTTrainer\nfrom datasets import Dataset\nimport json\nimport pandas as pd\nfrom transformers import Trainer, TrainingArguments\nfrom trl import PPOTrainer, PPOConfig, AutoModelForCausalLMWithValueHead, create_reference_model","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:55.931506Z","iopub.execute_input":"2023-10-23T07:22:55.931851Z","iopub.status.idle":"2023-10-23T07:22:55.939085Z","shell.execute_reply.started":"2023-10-23T07:22:55.931824Z","shell.execute_reply":"2023-10-23T07:22:55.937962Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, pipeline\nfrom datasets import Dataset\nimport torch\n","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:22:57.516031Z","iopub.execute_input":"2023-10-23T07:22:57.516399Z","iopub.status.idle":"2023-10-23T07:22:57.522294Z","shell.execute_reply.started":"2023-10-23T07:22:57.516369Z","shell.execute_reply":"2023-10-23T07:22:57.521310Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"##model path\nMODEL_PATH = \"rm_model/\"\nDATA_PATH = \"/kaggle/input/data-model-files/test_reward.parquet\"","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:23:02.187552Z","iopub.execute_input":"2023-10-23T07:23:02.188293Z","iopub.status.idle":"2023-10-23T07:23:02.193714Z","shell.execute_reply.started":"2023-10-23T07:23:02.188262Z","shell.execute_reply":"2023-10-23T07:23:02.192570Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"df = pd.read_parquet(DATA_PATH)\ndf = df[:1000]\n","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:56:05.957462Z","iopub.execute_input":"2023-10-23T07:56:05.957837Z","iopub.status.idle":"2023-10-23T07:56:06.149608Z","shell.execute_reply.started":"2023-10-23T07:56:05.957796Z","shell.execute_reply":"2023-10-23T07:56:06.148526Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"df.to_csv('prompts_data.csv')","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:56:07.414762Z","iopub.execute_input":"2023-10-23T07:56:07.416108Z","iopub.status.idle":"2023-10-23T07:56:07.502000Z","shell.execute_reply.started":"2023-10-23T07:56:07.416067Z","shell.execute_reply":"2023-10-23T07:56:07.500963Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:56:10.537050Z","iopub.execute_input":"2023-10-23T07:56:10.537908Z","iopub.status.idle":"2023-10-23T07:56:10.555250Z","shell.execute_reply.started":"2023-10-23T07:56:10.537863Z","shell.execute_reply":"2023-10-23T07:56:10.553042Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"                                                prompt  \\\n0    SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...   \n1    SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...   \n2    SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...   \n3    SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...   \n4    SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...   \n..                                                 ...   \n995  SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...   \n996  SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...   \n997  SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...   \n998  SUBREDDIT: r/relationships\\nTITLE: I (26M) am ...   \n999  SUBREDDIT: r/relationships\\nTITLE: I (26M) am ...   \n\n                                                chosen  \\\n0    TL;DR:  My Girlfriend of 15 months went throug...   \n1    TL;DR:  My girlfriend found messages in my Fac...   \n2    TL;DR:  My girlfriend found messages in my Fac...   \n3    TL;DR:  My Girlfriend of 15 months went throug...   \n4    TL;DR:  My girlfriend and I broke up after she...   \n..                                                 ...   \n995  TL;DR:  Met a girl, went on first date and had...   \n996  TL;DR:  Met a girl, went on first date and had...   \n997  TL;DR:  I [18M] just got cancelled on for my s...   \n998  TL;DR:  I (26M) am having a really hard time m...   \n999  TL;DR:  My girlfriend dumped me and I'm still ...   \n\n                                              rejected  \n0    TL;DR:  My girlfriend and I broke up after she...  \n1    TL;DR:  My girlfriend and I broke up after she...  \n2    TL;DR:  Girlfriend went through my Facebook ac...  \n3    TL;DR:  Girlfriend went through my Facebook ac...  \n4    TL;DR:  Girlfriend went through my Facebook ac...  \n..                                                 ...  \n995  TL;DR:  I [18M] just got cancelled on for my s...  \n996  TL;DR:  I [18M] just got cancelled on for my s...  \n997  TL;DR:  I [18M] just got cancelled on for my s...  \n998  TL;DR:  I can't seem to move on from my first ...  \n999  TL;DR:  girlfriend dumped me 3 months ago, I c...  \n\n[1000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>chosen</th>\n      <th>rejected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...</td>\n      <td>TL;DR:  My Girlfriend of 15 months went throug...</td>\n      <td>TL;DR:  My girlfriend and I broke up after she...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...</td>\n      <td>TL;DR:  My girlfriend found messages in my Fac...</td>\n      <td>TL;DR:  My girlfriend and I broke up after she...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...</td>\n      <td>TL;DR:  My girlfriend found messages in my Fac...</td>\n      <td>TL;DR:  Girlfriend went through my Facebook ac...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...</td>\n      <td>TL;DR:  My Girlfriend of 15 months went throug...</td>\n      <td>TL;DR:  Girlfriend went through my Facebook ac...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...</td>\n      <td>TL;DR:  My girlfriend and I broke up after she...</td>\n      <td>TL;DR:  Girlfriend went through my Facebook ac...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...</td>\n      <td>TL;DR:  Met a girl, went on first date and had...</td>\n      <td>TL;DR:  I [18M] just got cancelled on for my s...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...</td>\n      <td>TL;DR:  Met a girl, went on first date and had...</td>\n      <td>TL;DR:  I [18M] just got cancelled on for my s...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...</td>\n      <td>TL;DR:  I [18M] just got cancelled on for my s...</td>\n      <td>TL;DR:  I [18M] just got cancelled on for my s...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: I (26M) am ...</td>\n      <td>TL;DR:  I (26M) am having a really hard time m...</td>\n      <td>TL;DR:  I can't seem to move on from my first ...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: I (26M) am ...</td>\n      <td>TL;DR:  My girlfriend dumped me and I'm still ...</td>\n      <td>TL;DR:  girlfriend dumped me 3 months ago, I c...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install datasets==2.11.0","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:53:52.674610Z","iopub.execute_input":"2023-10-23T07:53:52.675385Z","iopub.status.idle":"2023-10-23T07:54:04.445605Z","shell.execute_reply.started":"2023-10-23T07:53:52.675347Z","shell.execute_reply":"2023-10-23T07:54:04.444356Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: datasets==2.11.0 in /opt/conda/lib/python3.10/site-packages (2.11.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (11.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (0.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11.0) (6.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11.0) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.11.0) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.11.0) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.11.0) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11.0) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11.0) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11.0) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11.0) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.11.0) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pandas==1.5.3","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:55:46.662885Z","iopub.execute_input":"2023-10-23T07:55:46.663756Z","iopub.status.idle":"2023-10-23T07:55:58.044908Z","shell.execute_reply.started":"2023-10-23T07:55:46.663712Z","shell.execute_reply":"2023-10-23T07:55:58.043770Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nRequirement already satisfied: pandas==1.5.3 in /opt/conda/lib/python3.10/site-packages (1.5.3)\nRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas==1.5.3) (1.23.5)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = load_dataset('csv',data_files='/kaggle/working/prompts_data.csv')\ndataset","metadata":{"execution":{"iopub.status.busy":"2023-10-23T07:56:57.510507Z","iopub.execute_input":"2023-10-23T07:56:57.510877Z","iopub.status.idle":"2023-10-23T07:56:57.832979Z","shell.execute_reply.started":"2023-10-23T07:56:57.510845Z","shell.execute_reply":"2023-10-23T07:56:57.831241Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-0c7de34caa552144/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c083cdfc6a6f491599f381928de77d99"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53c62af6170c4b4c99ca42c8ab022110"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[68], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcsv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/prompts_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m dataset\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/load.py:1691\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, ignore_verifications, keep_in_memory, save_infos, revision, use_auth_token, task, streaming, **config_kwargs)\u001b[0m\n\u001b[1;32m   1688\u001b[0m try_from_hf_gcs \u001b[38;5;241m=\u001b[39m path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   1690\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 1691\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_verifications\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_verifications\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_from_hf_gcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_from_hf_gcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1696\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_auth_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_auth_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1697\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1699\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1701\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   1702\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/builder.py:605\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, download_config, download_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHF google storage unreachable. Downloading and preparing it from source\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m downloaded_from_gcs:\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify_infos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_infos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/builder.py:694\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verify_infos, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m split_dict\u001b[38;5;241m.\u001b[39madd(split_generator\u001b[38;5;241m.\u001b[39msplit_info)\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;66;03m# Prepare split will record examples associated to the split\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find data file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_download_instructions \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    699\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOriginal error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    700\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)\n\u001b[1;32m    701\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/builder.py:1151\u001b[0m, in \u001b[0;36mArrowBasedBuilder._prepare_split\u001b[0;34m(self, split_generator)\u001b[0m\n\u001b[1;32m   1149\u001b[0m generator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_tables(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msplit_generator\u001b[38;5;241m.\u001b[39mgen_kwargs)\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ArrowWriter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mfeatures, path\u001b[38;5;241m=\u001b[39mfpath) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, table \u001b[38;5;129;01min\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(\n\u001b[1;32m   1152\u001b[0m         generator, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m tables\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# not logging.is_progress_bar_enabled()\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m     ):\n\u001b[1;32m   1154\u001b[0m         writer\u001b[38;5;241m.\u001b[39mwrite_table(table)\n\u001b[1;32m   1155\u001b[0m     num_examples, num_bytes \u001b[38;5;241m=\u001b[39m writer\u001b[38;5;241m.\u001b[39mfinalize()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1170\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[38;5;66;03m# If the bar is disabled, then just walk the iterable\u001b[39;00m\n\u001b[1;32m   1168\u001b[0m \u001b[38;5;66;03m# (note: keep this check outside the loop for performance)\u001b[39;00m\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable:\n\u001b[0;32m-> 1170\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1171\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1172\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/packaged_modules/csv/csv.py:154\u001b[0m, in \u001b[0;36mCsv._generate_tables\u001b[0;34m(self, files)\u001b[0m\n\u001b[1;32m    152\u001b[0m dtype \u001b[38;5;241m=\u001b[39m {name: dtype\u001b[38;5;241m.\u001b[39mto_pandas_dtype() \u001b[38;5;28;01mfor\u001b[39;00m name, dtype \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(schema\u001b[38;5;241m.\u001b[39mnames, schema\u001b[38;5;241m.\u001b[39mtypes)} \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file_idx, file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(files):\n\u001b[0;32m--> 154\u001b[0m     csv_file_reader \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, df \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(csv_file_reader):\n","\u001b[0;31mTypeError\u001b[0m: read_csv() got an unexpected keyword argument 'mangle_dupe_cols'"],"ename":"TypeError","evalue":"read_csv() got an unexpected keyword argument 'mangle_dupe_cols'","output_type":"error"}]},{"cell_type":"code","source":"#df = pd.read_parquet(DATA_PATH)\n#df = df[:1000]\n#dataset = Dataset.from_pandas(df)\n#dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:07:46.255963Z","iopub.execute_input":"2023-10-19T08:07:46.256576Z","iopub.status.idle":"2023-10-19T08:07:46.491516Z","shell.execute_reply.started":"2023-10-19T08:07:46.256545Z","shell.execute_reply":"2023-10-19T08:07:46.490532Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['prompt', 'chosen', 'rejected'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"df.dtypes\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:23:32.132601Z","iopub.execute_input":"2023-10-19T08:23:32.132959Z","iopub.status.idle":"2023-10-19T08:23:32.141679Z","shell.execute_reply.started":"2023-10-19T08:23:32.132933Z","shell.execute_reply":"2023-10-19T08:23:32.140577Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"prompt      object\nchosen      object\nrejected    object\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"df['prompt'] = df['prompt'].astype('str')\ndf['chosen'] = df['chosen'].astype('str')\ndf['rejected'] = df['rejected'].astype('str')\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:23:36.192595Z","iopub.execute_input":"2023-10-19T08:23:36.192958Z","iopub.status.idle":"2023-10-19T08:23:36.200821Z","shell.execute_reply.started":"2023-10-19T08:23:36.192933Z","shell.execute_reply":"2023-10-19T08:23:36.199747Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:23:49.524053Z","iopub.execute_input":"2023-10-19T08:23:49.524383Z","iopub.status.idle":"2023-10-19T08:23:49.546149Z","shell.execute_reply.started":"2023-10-19T08:23:49.524358Z","shell.execute_reply":"2023-10-19T08:23:49.545083Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000 entries, 0 to 999\nData columns (total 3 columns):\n #   Column    Non-Null Count  Dtype \n---  ------    --------------  ----- \n 0   prompt    1000 non-null   object\n 1   chosen    1000 non-null   object\n 2   rejected  1000 non-null   object\ndtypes: object(3)\nmemory usage: 23.6+ KB\n","output_type":"stream"}]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:23:27.635478Z","iopub.execute_input":"2023-10-19T08:23:27.636128Z","iopub.status.idle":"2023-10-19T08:23:27.649329Z","shell.execute_reply.started":"2023-10-19T08:23:27.636097Z","shell.execute_reply":"2023-10-19T08:23:27.648442Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"                                                prompt  \\\n0    SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...   \n1    SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...   \n2    SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...   \n3    SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...   \n4    SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...   \n..                                                 ...   \n995  SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...   \n996  SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...   \n997  SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...   \n998  SUBREDDIT: r/relationships\\nTITLE: I (26M) am ...   \n999  SUBREDDIT: r/relationships\\nTITLE: I (26M) am ...   \n\n                                                chosen  \\\n0    TL;DR:  My Girlfriend of 15 months went throug...   \n1    TL;DR:  My girlfriend found messages in my Fac...   \n2    TL;DR:  My girlfriend found messages in my Fac...   \n3    TL;DR:  My Girlfriend of 15 months went throug...   \n4    TL;DR:  My girlfriend and I broke up after she...   \n..                                                 ...   \n995  TL;DR:  Met a girl, went on first date and had...   \n996  TL;DR:  Met a girl, went on first date and had...   \n997  TL;DR:  I [18M] just got cancelled on for my s...   \n998  TL;DR:  I (26M) am having a really hard time m...   \n999  TL;DR:  My girlfriend dumped me and I'm still ...   \n\n                                              rejected  \n0    TL;DR:  My girlfriend and I broke up after she...  \n1    TL;DR:  My girlfriend and I broke up after she...  \n2    TL;DR:  Girlfriend went through my Facebook ac...  \n3    TL;DR:  Girlfriend went through my Facebook ac...  \n4    TL;DR:  Girlfriend went through my Facebook ac...  \n..                                                 ...  \n995  TL;DR:  I [18M] just got cancelled on for my s...  \n996  TL;DR:  I [18M] just got cancelled on for my s...  \n997  TL;DR:  I [18M] just got cancelled on for my s...  \n998  TL;DR:  I can't seem to move on from my first ...  \n999  TL;DR:  girlfriend dumped me 3 months ago, I c...  \n\n[1000 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>prompt</th>\n      <th>chosen</th>\n      <th>rejected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...</td>\n      <td>TL;DR:  My Girlfriend of 15 months went throug...</td>\n      <td>TL;DR:  My girlfriend and I broke up after she...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...</td>\n      <td>TL;DR:  My girlfriend found messages in my Fac...</td>\n      <td>TL;DR:  My girlfriend and I broke up after she...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...</td>\n      <td>TL;DR:  My girlfriend found messages in my Fac...</td>\n      <td>TL;DR:  Girlfriend went through my Facebook ac...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...</td>\n      <td>TL;DR:  My Girlfriend of 15 months went throug...</td>\n      <td>TL;DR:  Girlfriend went through my Facebook ac...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: My [21/M] g...</td>\n      <td>TL;DR:  My girlfriend and I broke up after she...</td>\n      <td>TL;DR:  Girlfriend went through my Facebook ac...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...</td>\n      <td>TL;DR:  Met a girl, went on first date and had...</td>\n      <td>TL;DR:  I [18M] just got cancelled on for my s...</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...</td>\n      <td>TL;DR:  Met a girl, went on first date and had...</td>\n      <td>TL;DR:  I [18M] just got cancelled on for my s...</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: I [18 M] ju...</td>\n      <td>TL;DR:  I [18M] just got cancelled on for my s...</td>\n      <td>TL;DR:  I [18M] just got cancelled on for my s...</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: I (26M) am ...</td>\n      <td>TL;DR:  I (26M) am having a really hard time m...</td>\n      <td>TL;DR:  I can't seem to move on from my first ...</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>SUBREDDIT: r/relationships\\nTITLE: I (26M) am ...</td>\n      <td>TL;DR:  My girlfriend dumped me and I'm still ...</td>\n      <td>TL;DR:  girlfriend dumped me 3 months ago, I c...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sentiment_pipe_kwargs = {\"top_k\": None, \"return_all_scores\": True,\"batch_size\": 16,\"function_to_apply\": \"none\"}\n\nconfig = PPOConfig(model_name=MODEL_PATH, steps=51200, learning_rate=1.41e-5)\n\ntxt_in_len = 5\ntxt_out_len = 20\nseed = 1","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:07:56.640573Z","iopub.execute_input":"2023-10-19T08:07:56.641447Z","iopub.status.idle":"2023-10-19T08:07:56.647365Z","shell.execute_reply.started":"2023-10-19T08:07:56.641414Z","shell.execute_reply":"2023-10-19T08:07:56.646244Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.rename_columns({\"prompt\": \"review\"})\ndataset = dataset.filter(lambda x: len(x[\"review\"]) > 500, batched=False)\ndataset = dataset.map(lambda x: {\"review\": x[\"review\"][:1000]}, batched=False)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:07:57.898398Z","iopub.execute_input":"2023-10-19T08:07:57.899062Z","iopub.status.idle":"2023-10-19T08:07:58.010901Z","shell.execute_reply.started":"2023-10-19T08:07:57.899033Z","shell.execute_reply":"2023-10-19T08:07:58.009888Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1574b1e5a42f403aa1f758159778d53a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98b796c623c6411b88ef970c846a7823"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, padding_side='left')\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:08:01.064609Z","iopub.execute_input":"2023-10-19T08:08:01.064986Z","iopub.status.idle":"2023-10-19T08:08:01.136204Z","shell.execute_reply.started":"2023-10-19T08:08:01.064959Z","shell.execute_reply":"2023-10-19T08:08:01.135231Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:10:48.744502Z","iopub.execute_input":"2023-10-19T08:10:48.744863Z","iopub.status.idle":"2023-10-19T08:10:48.752036Z","shell.execute_reply.started":"2023-10-19T08:10:48.744839Z","shell.execute_reply":"2023-10-19T08:10:48.751049Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['review', 'chosen', 'rejected', 'input_ids', 'query'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"print(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:20:41.375342Z","iopub.execute_input":"2023-10-19T08:20:41.375675Z","iopub.status.idle":"2023-10-19T08:20:41.382702Z","shell.execute_reply.started":"2023-10-19T08:20:41.375649Z","shell.execute_reply":"2023-10-19T08:20:41.381611Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['review', 'chosen', 'rejected', 'input_ids', 'query'],\n    num_rows: 1000\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"txt_in_len = 5\ntxt_out_len = 32\nseed = 1\n\ndataset = dataset.map(\n    lambda x: {\"input_ids\": tokenizer.encode(\" \" + x[\"chosen\"], return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=32)[0]},\n    batched=False,\n)\ndataset = dataset.map(lambda x: {\"query\": tokenizer.decode(x[\"input_ids\"])}, batched=False)\n#dataset = dataset[:20480]\n\n#dataset = Dataset.from_dict(dataset)\ndataset.set_format(\"pytorch\")","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:08:02.418243Z","iopub.execute_input":"2023-10-19T08:08:02.419011Z","iopub.status.idle":"2023-10-19T08:08:03.138808Z","shell.execute_reply.started":"2023-10-19T08:08:02.418982Z","shell.execute_reply":"2023-10-19T08:08:03.137797Z"},"trusted":true},"execution_count":42,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36aa0f6d79034aac8b171b2cdf717881"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1000 [00:00<?, ?ex/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6a8b2f91aeb4a47a7c8710236c6c9b2"}},"metadata":{}}]},{"cell_type":"code","source":"dataset.set_format(type='torch',columns=['review', 'chosen', 'rejected', 'input_ids', 'query'])","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:11:28.750913Z","iopub.execute_input":"2023-10-19T08:11:28.751244Z","iopub.status.idle":"2023-10-19T08:11:28.758007Z","shell.execute_reply.started":"2023-10-19T08:11:28.751219Z","shell.execute_reply":"2023-10-19T08:11:28.756878Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"dataloader = torch.utils.data.DataLoader(dataset, batch_size=32)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:11:32.370758Z","iopub.execute_input":"2023-10-19T08:11:32.371072Z","iopub.status.idle":"2023-10-19T08:11:32.376861Z","shell.execute_reply.started":"2023-10-19T08:11:32.371049Z","shell.execute_reply":"2023-10-19T08:11:32.375665Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"iter(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:54:28.372714Z","iopub.execute_input":"2023-10-19T08:54:28.373054Z","iopub.status.idle":"2023-10-19T08:54:28.380764Z","shell.execute_reply.started":"2023-10-19T08:54:28.373030Z","shell.execute_reply":"2023-10-19T08:54:28.379995Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader._SingleProcessDataLoaderIter at 0x7bc516228310>"},"metadata":{}}]},{"cell_type":"code","source":"dataloader['review']","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:30:19.963087Z","iopub.execute_input":"2023-10-19T08:30:19.963895Z","iopub.status.idle":"2023-10-19T08:30:20.007982Z","shell.execute_reply.started":"2023-10-19T08:30:19.963865Z","shell.execute_reply":"2023-10-19T08:30:20.006453Z"},"trusted":true},"execution_count":57,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[57], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdataloader\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreview\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"],"ename":"TypeError","evalue":"'DataLoader' object is not subscriptable","output_type":"error"}]},{"cell_type":"code","source":"next(iter(dataloader))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T08:11:34.688354Z","iopub.execute_input":"2023-10-19T08:11:34.688656Z","iopub.status.idle":"2023-10-19T08:11:34.833147Z","shell.execute_reply.started":"2023-10-19T08:11:34.688634Z","shell.execute_reply":"2023-10-19T08:11:34.831617Z"},"trusted":true},"execution_count":50,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1764\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1749\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, decoded\u001b[38;5;241m=\u001b[39mdecoded, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   1748\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1749\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:540\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    539\u001b[0m     pa_table_to_format \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mdrop(col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mcolumn_names \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m format_columns)\n\u001b[0;32m--> 540\u001b[0m     formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table_to_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_all_columns:\n\u001b[1;32m    542\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_output, MutableMapping):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:281\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:58\u001b[0m, in \u001b[0;36mTorchFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     57\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:54\u001b[0m, in \u001b[0;36mTorchFormatter.recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_tensorize\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_struct: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_tensorize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:314\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    312\u001b[0m     num_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m num_proc:\n\u001b[0;32m--> 314\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    315\u001b[0m         _single_map_nested((function, obj, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    317\u001b[0m     ]\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     split_kwds \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# We organize the splits ourselve (contiguous splits)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m     num_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m num_proc:\n\u001b[1;32m    314\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 315\u001b[0m         \u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    317\u001b[0m     ]\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     split_kwds \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# We organize the splits ourselve (contiguous splits)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:251\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Singleton first to spare some computation\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:51\u001b[0m, in \u001b[0;36mTorchFormatter._recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_struct\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject:  \u001b[38;5;66;03m# pytorch tensors cannot be instantied from an array of objects\u001b[39;00m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecursive_tensorize(substruct) \u001b[38;5;28;01mfor\u001b[39;00m substruct \u001b[38;5;129;01min\u001b[39;00m data_struct]\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:43\u001b[0m, in \u001b[0;36mTorchFormatter._tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(value\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m     41\u001b[0m     default_dtype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_tensor_kwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'numpy.str_'"],"ename":"TypeError","evalue":"new(): invalid data type 'numpy.str_'","output_type":"error"}]},{"cell_type":"code","source":"type(dataset['chosen'])","metadata":{"execution":{"iopub.status.busy":"2023-10-18T09:48:59.711180Z","iopub.execute_input":"2023-10-18T09:48:59.711880Z","iopub.status.idle":"2023-10-18T09:48:59.812288Z","shell.execute_reply.started":"2023-10-18T09:48:59.711848Z","shell.execute_reply":"2023-10-18T09:48:59.811252Z"},"trusted":true},"execution_count":72,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[72], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchosen\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1764\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1749\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, decoded\u001b[38;5;241m=\u001b[39mdecoded, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   1748\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1749\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:532\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:283\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_batch(pa_table)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:62\u001b[0m, in \u001b[0;36mTorchFormatter.format_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     61\u001b[0m     col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_column(pa_table)\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:54\u001b[0m, in \u001b[0;36mTorchFormatter.recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_tensorize\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_struct: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_tensorize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:306\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Singleton\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m disable_tqdm \u001b[38;5;241m=\u001b[39m disable_tqdm \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m    309\u001b[0m iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data_struct\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m data_struct\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:51\u001b[0m, in \u001b[0;36mTorchFormatter._recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_struct\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject:  \u001b[38;5;66;03m# pytorch tensors cannot be instantied from an array of objects\u001b[39;00m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecursive_tensorize(substruct) \u001b[38;5;28;01mfor\u001b[39;00m substruct \u001b[38;5;129;01min\u001b[39;00m data_struct]\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:43\u001b[0m, in \u001b[0;36mTorchFormatter._tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(value\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m     41\u001b[0m     default_dtype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_tensor_kwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."],"ename":"TypeError","evalue":"can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.","output_type":"error"}]},{"cell_type":"code","source":"def collator(data):\n    return dict((key, [d[key] for d in data]) for key in data[0])","metadata":{"execution":{"iopub.status.busy":"2023-10-18T07:59:27.862198Z","iopub.execute_input":"2023-10-18T07:59:27.862918Z","iopub.status.idle":"2023-10-18T07:59:27.868721Z","shell.execute_reply.started":"2023-10-18T07:59:27.862883Z","shell.execute_reply":"2023-10-18T07:59:27.867911Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"print(dataset)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T07:59:41.291343Z","iopub.execute_input":"2023-10-18T07:59:41.292167Z","iopub.status.idle":"2023-10-18T07:59:41.298129Z","shell.execute_reply.started":"2023-10-18T07:59:41.292131Z","shell.execute_reply":"2023-10-18T07:59:41.297340Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['review', 'chosen', 'rejected', 'input_ids', 'query'],\n    num_rows: 1000\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"#print(type(dataset['review']))\n#print(type(dataset['chosen']))\nprint(type(dataset['rejected']))\nprint(type(dataset['input_ids']))\nprint(type(dataset['query']))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-18T09:51:29.222036Z","iopub.execute_input":"2023-10-18T09:51:29.222839Z","iopub.status.idle":"2023-10-18T09:51:29.319302Z","shell.execute_reply.started":"2023-10-18T09:51:29.222806Z","shell.execute_reply":"2023-10-18T09:51:29.317286Z"},"trusted":true},"execution_count":76,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[76], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#print(type(dataset['review']))\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#print(type(dataset['chosen']))\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrejected\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1764\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1749\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, decoded\u001b[38;5;241m=\u001b[39mdecoded, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   1748\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1749\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:532\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:283\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_row(pa_table)\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_batch(pa_table)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:62\u001b[0m, in \u001b[0;36mTorchFormatter.format_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.Tensor\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     61\u001b[0m     col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_column(pa_table)\n\u001b[0;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:54\u001b[0m, in \u001b[0;36mTorchFormatter.recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_tensorize\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_struct: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_tensorize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:306\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;66;03m# Singleton\u001b[39;00m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 306\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m disable_tqdm \u001b[38;5;241m=\u001b[39m disable_tqdm \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m    309\u001b[0m iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(data_struct\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m data_struct\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:51\u001b[0m, in \u001b[0;36mTorchFormatter._recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_struct\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject:  \u001b[38;5;66;03m# pytorch tensors cannot be instantied from an array of objects\u001b[39;00m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecursive_tensorize(substruct) \u001b[38;5;28;01mfor\u001b[39;00m substruct \u001b[38;5;129;01min\u001b[39;00m data_struct]\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:43\u001b[0m, in \u001b[0;36mTorchFormatter._tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(value\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m     41\u001b[0m     default_dtype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_tensor_kwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."],"ename":"TypeError","evalue":"can't convert np.ndarray of type numpy.str_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.","output_type":"error"}]},{"cell_type":"code","source":"rf_model_path = \"rm_model/\"\nstarcoder_model = AutoModelForCausalLMWithValueHead.from_pretrained(rf_model_path)\nstarcoder_model_ref = AutoModelForCausalLMWithValueHead.from_pretrained(rf_model_path)\nstarcoder_tokenizer = AutoTokenizer.from_pretrained(rf_model_path)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T07:59:55.811493Z","iopub.execute_input":"2023-10-18T07:59:55.812172Z","iopub.status.idle":"2023-10-18T08:00:00.823384Z","shell.execute_reply.started":"2023-10-18T07:59:55.812141Z","shell.execute_reply":"2023-10-18T08:00:00.821569Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:01:59.166956Z","iopub.execute_input":"2023-10-18T08:01:59.167296Z","iopub.status.idle":"2023-10-18T08:01:59.174996Z","shell.execute_reply.started":"2023-10-18T08:01:59.167270Z","shell.execute_reply":"2023-10-18T08:01:59.174232Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['review', 'chosen', 'rejected', 'input_ids', 'query'],\n    num_rows: 1000\n})"},"metadata":{}}]},{"cell_type":"code","source":"#optimizer = torch.optim.SGD(starcoder_model.parameters(), lr=config.learning_rate)\nppo_trainer = PPOTrainer(config, starcoder_model, starcoder_model_ref, starcoder_tokenizer, dataset=dataset, data_collator=collator)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:02:05.833556Z","iopub.execute_input":"2023-10-18T08:02:05.834195Z","iopub.status.idle":"2023-10-18T08:02:06.245968Z","shell.execute_reply.started":"2023-10-18T08:02:05.834165Z","shell.execute_reply":"2023-10-18T08:02:06.245231Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"ctrl_str = [\"[negative]\", \"[positive]\"]\ndevice = ppo_trainer.accelerator.device\nif ppo_trainer.accelerator.num_processes == 1:\n    device = 0 if torch.cuda.is_available() else \"cpu\" \n#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # this should be handled by accelerate\nctrl_tokens = dict((s, starcoder_tokenizer.encode(s, return_tensors=\"pt\").squeeze().to(device)) for s in ctrl_str)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:03:07.211653Z","iopub.execute_input":"2023-10-18T08:03:07.211958Z","iopub.status.idle":"2023-10-18T08:03:07.218349Z","shell.execute_reply.started":"2023-10-18T08:03:07.211937Z","shell.execute_reply":"2023-10-18T08:03:07.217518Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def pos_logit_to_reward(logit, task):\n    \"\"\"\n    Take the positive sentiment logit and scale it for the task.\n        task [negative]: reward = -logit\n        task [neutral]: reward = -2*abs(logit)+4\n        task [positive]: reward = logit\n    \"\"\"\n    for i in range(len(logit)):\n        if task[i] == \"[negative]\":\n            logit[i] = -logit[i]\n        elif task[i] == \"[positive]\":\n            pass\n        else:\n            raise ValueError(\"task has to be in [0, 1, 2]!\")\n    return logit","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:03:08.381581Z","iopub.execute_input":"2023-10-18T08:03:08.382211Z","iopub.status.idle":"2023-10-18T08:03:08.387775Z","shell.execute_reply.started":"2023-10-18T08:03:08.382181Z","shell.execute_reply":"2023-10-18T08:03:08.387109Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"pos_logit_to_reward(torch.Tensor([4, 4]), ctrl_str)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:03:09.074512Z","iopub.execute_input":"2023-10-18T08:03:09.075073Z","iopub.status.idle":"2023-10-18T08:03:09.089481Z","shell.execute_reply.started":"2023-10-18T08:03:09.075045Z","shell.execute_reply":"2023-10-18T08:03:09.088810Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"tensor([-4.,  4.])"},"metadata":{}}]},{"cell_type":"code","source":"generation_kwargs = {\n    \"min_length\": -1,\n    \"top_k\": 0.0,\n    \"top_p\": 1.0,\n    \"do_sample\": True,\n    \"pad_token_id\": starcoder_tokenizer.eos_token_id,\n    \"max_new_tokens\": 32,\n    \"eos_token_id\": -1,\n}","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:03:27.591042Z","iopub.execute_input":"2023-10-18T08:03:27.591907Z","iopub.status.idle":"2023-10-18T08:03:27.597636Z","shell.execute_reply.started":"2023-10-18T08:03:27.591873Z","shell.execute_reply":"2023-10-18T08:03:27.596666Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"def get_score(model, tokenizer, responses):\n    positive_logist = []\n    for i in responses:\n        instructions = tokenizer.encode_plus(\n                                           i,\n                                           padding=\"max_length\",\n                                           max_length=32,\n                                           return_tensors=\"pt\")\n        with torch.no_grad():\n            outputs = model(**instructions)\n\n        logits = outputs[0].mean()\n        positive_logist.append(logits)\n\n    return positive_logist\n","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:03:41.463568Z","iopub.execute_input":"2023-10-18T08:03:41.463941Z","iopub.status.idle":"2023-10-18T08:03:41.470581Z","shell.execute_reply.started":"2023-10-18T08:03:41.463912Z","shell.execute_reply":"2023-10-18T08:03:41.469567Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"from random import choices\nfrom tqdm import tqdm\nimport time\nimport numpy as np\ntqdm.pandas()","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:04:32.547139Z","iopub.execute_input":"2023-10-18T08:04:32.547762Z","iopub.status.idle":"2023-10-18T08:04:32.556725Z","shell.execute_reply.started":"2023-10-18T08:04:32.547735Z","shell.execute_reply":"2023-10-18T08:04:32.555992Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"type(ppo_trainer)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:16:25.187869Z","iopub.execute_input":"2023-10-18T08:16:25.188849Z","iopub.status.idle":"2023-10-18T08:16:25.196762Z","shell.execute_reply.started":"2023-10-18T08:16:25.188814Z","shell.execute_reply":"2023-10-18T08:16:25.196074Z"},"trusted":true},"execution_count":60,"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"trl.trainer.ppo_trainer.PPOTrainer"},"metadata":{}}]},{"cell_type":"code","source":"type(ppo_trainer.dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:16:45.034625Z","iopub.execute_input":"2023-10-18T08:16:45.035248Z","iopub.status.idle":"2023-10-18T08:16:45.041375Z","shell.execute_reply.started":"2023-10-18T08:16:45.035219Z","shell.execute_reply":"2023-10-18T08:16:45.040686Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"accelerate.data_loader.DataLoaderShard"},"metadata":{}}]},{"cell_type":"code","source":"for epoch in range(1):\n    print(epoch)\n    for batch in tqdm(ppo_trainer.dataloader):\n        print(batch)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T09:27:36.535819Z","iopub.execute_input":"2023-10-18T09:27:36.536516Z","iopub.status.idle":"2023-10-18T09:27:36.720541Z","shell.execute_reply.started":"2023-10-18T09:27:36.536484Z","shell.execute_reply":"2023-10-18T09:27:36.718290Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"},{"name":"stderr","text":"  0%|          | 0/3 [00:00<?, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[69], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(epoch)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(ppo_trainer\u001b[38;5;241m.\u001b[39mdataloader):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28mprint\u001b[39m(batch)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/data_loader.py:384\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1764\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1749\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, decoded\u001b[38;5;241m=\u001b[39mdecoded, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   1748\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1749\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:532\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:281\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:58\u001b[0m, in \u001b[0;36mTorchFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     57\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:54\u001b[0m, in \u001b[0;36mTorchFormatter.recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_tensorize\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_struct: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_tensorize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:314\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    312\u001b[0m     num_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m num_proc:\n\u001b[0;32m--> 314\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    315\u001b[0m         _single_map_nested((function, obj, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    317\u001b[0m     ]\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     split_kwds \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# We organize the splits ourselve (contiguous splits)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m     num_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m num_proc:\n\u001b[1;32m    314\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 315\u001b[0m         \u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    317\u001b[0m     ]\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     split_kwds \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# We organize the splits ourselve (contiguous splits)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:251\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Singleton first to spare some computation\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:51\u001b[0m, in \u001b[0;36mTorchFormatter._recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_struct\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject:  \u001b[38;5;66;03m# pytorch tensors cannot be instantied from an array of objects\u001b[39;00m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecursive_tensorize(substruct) \u001b[38;5;28;01mfor\u001b[39;00m substruct \u001b[38;5;129;01min\u001b[39;00m data_struct]\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:43\u001b[0m, in \u001b[0;36mTorchFormatter._tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(value\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m     41\u001b[0m     default_dtype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_tensor_kwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'numpy.str_'"],"ename":"TypeError","evalue":"new(): invalid data type 'numpy.str_'","output_type":"error"}]},{"cell_type":"code","source":"for epoch,batch in tqdm(enumerate(ppo_trainer.dataloader)):\n    print(type(epoch))\n    print(type(batch))","metadata":{"execution":{"iopub.status.busy":"2023-10-18T09:20:31.735146Z","iopub.execute_input":"2023-10-18T09:20:31.735795Z","iopub.status.idle":"2023-10-18T09:20:31.891709Z","shell.execute_reply.started":"2023-10-18T09:20:31.735767Z","shell.execute_reply":"2023-10-18T09:20:31.890604Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stderr","text":"0it [00:00, ?it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[67], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch,batch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(ppo_trainer\u001b[38;5;241m.\u001b[39mdataloader)):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(epoch))\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(batch))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/data_loader.py:384\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 384\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1764\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   1763\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/arrow_dataset.py:1749\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[1;32m   1747\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures, decoded\u001b[38;5;241m=\u001b[39mdecoded, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   1748\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1749\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:532\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    530\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    534\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/formatting.py:281\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 281\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:58\u001b[0m, in \u001b[0;36mTorchFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     57\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:54\u001b[0m, in \u001b[0;36mTorchFormatter.recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_tensorize\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_struct: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_tensorize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:314\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    312\u001b[0m     num_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m num_proc:\n\u001b[0;32m--> 314\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    315\u001b[0m         _single_map_nested((function, obj, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    317\u001b[0m     ]\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     split_kwds \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# We organize the splits ourselve (contiguous splits)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:315\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m     num_proc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m num_proc:\n\u001b[1;32m    314\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 315\u001b[0m         \u001b[43m_single_map_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mtqdm(iterable, disable\u001b[38;5;241m=\u001b[39mdisable_tqdm, desc\u001b[38;5;241m=\u001b[39mdesc)\n\u001b[1;32m    317\u001b[0m     ]\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m     split_kwds \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# We organize the splits ourselve (contiguous splits)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/utils/py_utils.py:251\u001b[0m, in \u001b[0;36m_single_map_nested\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# Singleton first to spare some computation\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, types):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# Reduce logging to keep things readable in multiprocessing with tqdm\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mget_verbosity() \u001b[38;5;241m<\u001b[39m logging\u001b[38;5;241m.\u001b[39mWARNING:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:51\u001b[0m, in \u001b[0;36mTorchFormatter._recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_struct\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mobject:  \u001b[38;5;66;03m# pytorch tensors cannot be instantied from an array of objects\u001b[39;00m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecursive_tensorize(substruct) \u001b[38;5;28;01mfor\u001b[39;00m substruct \u001b[38;5;129;01min\u001b[39;00m data_struct]\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:43\u001b[0m, in \u001b[0;36mTorchFormatter._tensorize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(value\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mfloating):\n\u001b[1;32m     41\u001b[0m     default_dtype \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: torch\u001b[38;5;241m.\u001b[39mfloat32}\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdefault_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch_tensor_kwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mTypeError\u001b[0m: new(): invalid data type 'numpy.str_'"],"ename":"TypeError","evalue":"new(): invalid data type 'numpy.str_'","output_type":"error"}]},{"cell_type":"code","source":"print(ppo_trainer.dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T08:28:43.887154Z","iopub.execute_input":"2023-10-18T08:28:43.887754Z","iopub.status.idle":"2023-10-18T08:28:43.896626Z","shell.execute_reply.started":"2023-10-18T08:28:43.887726Z","shell.execute_reply":"2023-10-18T08:28:43.895938Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"<accelerate.data_loader.DataLoaderShard object at 0x79e021186d70>\n","output_type":"stream"}]},{"cell_type":"code","source":"for epoch,batch in tqdm(enumerate(ppo_trainer.dataloader)):\n    print(epoch)\n    print(batch)","metadata":{},"execution_count":null,"outputs":[]}]}