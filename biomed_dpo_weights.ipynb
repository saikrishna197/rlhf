{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07d1a89-78b3-49f3-a6d7-6b6c9a36f830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments\n",
    "\n",
    "from trl import SFTTrainer\n",
    "from trl.trainer import ConstantLengthDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab573a1-cdb9-4153-870f-d798fca93dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f4470d743b472a9e92ae7ea07088cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()  # same as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2e9e2e3-8313-4cbc-9713-0d4cc5d1fc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. imports\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig\n",
    "from transformers import AutoTokenizer, HfArgumentParser, TrainingArguments\n",
    "\n",
    "from trl import DPOTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe58e8e3-263b-4f8d-be4a-2bb1ac418c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bdfc136-769a-4ed9-9ae5-80eb1547e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#dataset = load_dataset(\"Dahoas/full-hh-rlhf\",split='test')\n",
    "dataset = load_dataset('json',data_files='mungeo_dp.jsonl',split = \"train\",use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae7abde9-3176-457b-95c0-944faabaa5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'response', 'chosen', 'rejected'],\n",
       "    num_rows: 231\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7900757-d4f1-476f-8c60-2fce336eab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Dataset = pd.read_csv('data_dpo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9224c20-d931-4a61-b7bc-376d9e2a3f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>The patient's diagnosis is chronic inflammator...</td>\n",
       "      <td>Primary Diagnosis: Chronic inflammatory demyel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the given information, it is mentione...</td>\n",
       "      <td>The patient's diagnosis of CIDP has been confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the given information, it is stated t...</td>\n",
       "      <td>The patient's diagnosis of CIDP has been confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the given medical context, there is n...</td>\n",
       "      <td>The patient has not tried conventional therapy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the provided context, there is no inf...</td>\n",
       "      <td>The patient's current weight in kilograms (kg)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the provided medical context, there i...</td>\n",
       "      <td>Given the provided medical context and the age...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the provided context, it is indicated...</td>\n",
       "      <td>The patient's medical status does not require ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the provided context, it is not possi...</td>\n",
       "      <td>The patient is at risk for fluid overload and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the provided medical context, there i...</td>\n",
       "      <td>The context provided does not contain any sign...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>No, the given context does not provide enough ...</td>\n",
       "      <td>Given the medical context provided, the patien...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0    [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "1    [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "2    [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "3    [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "4    [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "..                                                 ...   \n",
       "226  [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "227  [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "228  [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "229  [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "230  [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "\n",
       "                                                chosen  \\\n",
       "0    The patient's diagnosis is chronic inflammator...   \n",
       "1    Based on the given information, it is mentione...   \n",
       "2    Based on the given information, it is stated t...   \n",
       "3    Based on the given medical context, there is n...   \n",
       "4    Based on the provided context, there is no inf...   \n",
       "..                                                 ...   \n",
       "226  Based on the provided medical context, there i...   \n",
       "227  Based on the provided context, it is indicated...   \n",
       "228  Based on the provided context, it is not possi...   \n",
       "229  Based on the provided medical context, there i...   \n",
       "230  No, the given context does not provide enough ...   \n",
       "\n",
       "                                              rejected  \n",
       "0    Primary Diagnosis: Chronic inflammatory demyel...  \n",
       "1    The patient's diagnosis of CIDP has been confi...  \n",
       "2    The patient's diagnosis of CIDP has been confi...  \n",
       "3    The patient has not tried conventional therapy...  \n",
       "4    The patient's current weight in kilograms (kg)...  \n",
       "..                                                 ...  \n",
       "226  Given the provided medical context and the age...  \n",
       "227  The patient's medical status does not require ...  \n",
       "228  The patient is at risk for fluid overload and ...  \n",
       "229  The context provided does not contain any sign...  \n",
       "230  Given the medical context provided, the patien...  \n",
       "\n",
       "[231 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ce1efc4-1d47-4964-b373-b8e48cb8d550",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.to_json('dp0.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a22e658-0ee8-43a4-a7e9-3d7fa0a0b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('dp0.json')\n",
    "df.to_json(\"dpo.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5ed5893-8cfd-443d-8750-1ebc7690418b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/ppo/lib/python3.9/site-packages/datasets/load.py:2089: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=True' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "#dataset = load_dataset(\"Dahoas/full-hh-rlhf\",split='test')\n",
    "dataset = load_dataset('json',data_files='dpo.jsonl',split = \"train\",use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aafe93c-c14b-44d3-bb71-482613bd4701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 231\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1ac6260-c7c7-44fb-8071-31f1bf82ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns = dataset.column_names\n",
    "\n",
    "def return_prompt_and_responses(samples):\n",
    "    return {\n",
    "        \"prompt\": samples['prompt'],\n",
    "        \"chosen\": samples[\"chosen\"],\n",
    "        \"rejected\": samples[\"rejected\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e93624-3942-46da-b62f-7f14cfe2b9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.map(return_prompt_and_responses,batched=True,remove_columns=original_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7002875-0d32-420b-a968-d88f9dbf7b9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 231\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0000c52-1233-4da5-a9ef-37651bd82245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "683b67e4afe04f18a937bfc9d68e2564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. load a pretrained model\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\"/home/jovyan/sai/sft_biomedgpt7b\",low_cpu_mem_usage=True,torch_dtype=torch.float16,load_in_4bit=True)\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffa90d4a-6e8a-4a89-a214-badfc2886b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d54e82694354ae9b5892bb6fb207b4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the reference model \n",
    "model_ref = AutoPeftModelForCausalLM.from_pretrained(\"/home/jovyan/sai/sft_biomedgpt7b\",low_cpu_mem_usage=True,torch_dtype=torch.float16,load_in_4bit=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7f96a1b-62d4-43e7-9e4b-f6b57e26e348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): LlamaForCausalLM(\n",
       "      (model): LlamaModel(\n",
       "        (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x LlamaDecoderLayer(\n",
       "            (self_attn): LlamaAttention(\n",
       "              (q_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(\n",
       "                in_features=4096, out_features=4096, bias=False\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.05, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (rotary_emb): LlamaRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): LlamaMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
       "              (act_fn): SiLUActivation()\n",
       "            )\n",
       "            (input_layernorm): LlamaRMSNorm()\n",
       "            (post_attention_layernorm): LlamaRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): LlamaRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1805b03a-79d6-4664-90c7-c891043e7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/jovyan/sai/sft_biomedgpt7b\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acec704-a2f0-4510-93b1-3452863ef716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer: PreTrainedTokenizer = AutoTokenizer.from_pretrained('distilroberta-base')\n",
    "tokenizer.model_max_length = sys.maxsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1546b32-2316-4206-9bf8-8a76bc2b5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_data.to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "761813e4-6afb-4614-8e66-6490225b4919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>The patient's diagnosis is chronic inflammator...</td>\n",
       "      <td>Primary Diagnosis: Chronic inflammatory demyel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the given information, it is mentione...</td>\n",
       "      <td>The patient's diagnosis of CIDP has been confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the given information, it is stated t...</td>\n",
       "      <td>The patient's diagnosis of CIDP has been confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the given medical context, there is n...</td>\n",
       "      <td>The patient has not tried conventional therapy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[INST]&lt;&lt;SYS&gt;&gt;\\n You are a helpful, respectful ...</td>\n",
       "      <td>Based on the provided context, there is no inf...</td>\n",
       "      <td>The patient's current weight in kilograms (kg)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "1  [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "2  [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "3  [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "4  [INST]<<SYS>>\\n You are a helpful, respectful ...   \n",
       "\n",
       "                                              chosen  \\\n",
       "0  The patient's diagnosis is chronic inflammator...   \n",
       "1  Based on the given information, it is mentione...   \n",
       "2  Based on the given information, it is stated t...   \n",
       "3  Based on the given medical context, there is n...   \n",
       "4  Based on the provided context, there is no inf...   \n",
       "\n",
       "                                            rejected  \n",
       "0  Primary Diagnosis: Chronic inflammatory demyel...  \n",
       "1  The patient's diagnosis of CIDP has been confi...  \n",
       "2  The patient's diagnosis of CIDP has been confi...  \n",
       "3  The patient has not tried conventional therapy...  \n",
       "4  The patient's current weight in kilograms (kg)...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f69c622-2fb3-4118-b599-8a3d1538df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = train_df.sample(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd37d069-2dd9-4cba-b9c6-9d6e95ec17db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = dataset.from_pandas(train_df)\n",
    "val_data = dataset.from_pandas(val_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c19a5e7b-ac80-4f89-855a-a503bee63eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        r=4,\n",
    "        lora_alpha=6,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules=[\"q_proj\", \"k_proj\",\"v_proj\",\"o_proj\"],\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "    )\n",
    "peft_config.inference_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89ec863f-6840-4fca-872f-714153dfe8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import AutoPeftModelForCausalLM, LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model.config.use_cache=False\n",
    "model.gradient_checkpointing_enable()\n",
    "model.config.pretraining_tp=1\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bebeec07-14ac-4211-88c8-b7f3d19cfaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ref = prepare_model_for_kbit_training(model_ref)\n",
    "model_ref.config.use_cache=False\n",
    "model_ref.gradient_checkpointing_enable()\n",
    "model_ref.config.pretraining_tp=1\n",
    "model_ref = get_peft_model(model_ref, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1d81f61-6828-4b75-8679-532057ce0773",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        max_steps=250,\n",
    "        remove_unused_columns=False,\n",
    "        gradient_accumulation_steps=1,\n",
    "        learning_rate=2e-4,\n",
    "        evaluation_strategy=\"steps\",\n",
    "        logging_first_step=True,\n",
    "        logging_steps=10,\n",
    "        output_dir=\"biomedgpt_dpo7b\",\n",
    "        optim=\"paged_adamw_32bit\",\n",
    "        warmup_steps=2,\n",
    "        fp16=True,\n",
    "        #push_to_hub=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e167620-b97e-450e-839e-fa7f23598b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer = DPOTrainer(\n",
    "        model,\n",
    "        model_ref,\n",
    "        args=training_args,\n",
    "        beta=0.1,\n",
    "        train_dataset=train_data,\n",
    "        eval_dataset=val_data,\n",
    "        tokenizer=tokenizer,\n",
    "        max_length=512,\n",
    "        #max_target_length=256,\n",
    "        max_prompt_length=256\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "922737e6-e598-4551-bdb7-8f91923aab56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/ppo/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [250/250 54:15, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.594100</td>\n",
       "      <td>0.442721</td>\n",
       "      <td>0.730242</td>\n",
       "      <td>-0.014264</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.744505</td>\n",
       "      <td>-49.035248</td>\n",
       "      <td>-76.145126</td>\n",
       "      <td>-1.949236</td>\n",
       "      <td>-1.962515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.289500</td>\n",
       "      <td>0.168533</td>\n",
       "      <td>1.596395</td>\n",
       "      <td>-1.008335</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>2.604729</td>\n",
       "      <td>-58.975956</td>\n",
       "      <td>-67.483604</td>\n",
       "      <td>-1.956141</td>\n",
       "      <td>-1.996064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.090600</td>\n",
       "      <td>0.113443</td>\n",
       "      <td>1.074785</td>\n",
       "      <td>-4.117273</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>5.192058</td>\n",
       "      <td>-90.065338</td>\n",
       "      <td>-72.699707</td>\n",
       "      <td>-1.895948</td>\n",
       "      <td>-1.966324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.628800</td>\n",
       "      <td>0.110923</td>\n",
       "      <td>1.302094</td>\n",
       "      <td>-5.209227</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>6.511321</td>\n",
       "      <td>-100.984879</td>\n",
       "      <td>-70.426613</td>\n",
       "      <td>-1.855031</td>\n",
       "      <td>-1.970084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.233000</td>\n",
       "      <td>0.131741</td>\n",
       "      <td>0.871220</td>\n",
       "      <td>-8.501960</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>9.373180</td>\n",
       "      <td>-133.912201</td>\n",
       "      <td>-74.735352</td>\n",
       "      <td>-1.832937</td>\n",
       "      <td>-1.975735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.307665</td>\n",
       "      <td>-4.165074</td>\n",
       "      <td>-19.973728</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>15.808652</td>\n",
       "      <td>-248.629868</td>\n",
       "      <td>-125.098282</td>\n",
       "      <td>-1.733528</td>\n",
       "      <td>-1.827126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.454582</td>\n",
       "      <td>-2.995451</td>\n",
       "      <td>-24.444614</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>21.449163</td>\n",
       "      <td>-293.338745</td>\n",
       "      <td>-113.402069</td>\n",
       "      <td>-1.726159</td>\n",
       "      <td>-1.886185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.898774</td>\n",
       "      <td>-7.331526</td>\n",
       "      <td>-42.742233</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>35.410702</td>\n",
       "      <td>-476.314880</td>\n",
       "      <td>-156.762802</td>\n",
       "      <td>-1.566082</td>\n",
       "      <td>-1.741032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.693646</td>\n",
       "      <td>-12.795603</td>\n",
       "      <td>-66.479172</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>53.683571</td>\n",
       "      <td>-713.684265</td>\n",
       "      <td>-211.403564</td>\n",
       "      <td>-1.555425</td>\n",
       "      <td>-1.678339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.760300</td>\n",
       "      <td>0.656771</td>\n",
       "      <td>-4.551429</td>\n",
       "      <td>-43.349770</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>38.798340</td>\n",
       "      <td>-482.390320</td>\n",
       "      <td>-128.961838</td>\n",
       "      <td>-1.751012</td>\n",
       "      <td>-1.982707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.282500</td>\n",
       "      <td>0.352599</td>\n",
       "      <td>-0.681367</td>\n",
       "      <td>-18.981203</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>18.299835</td>\n",
       "      <td>-238.704620</td>\n",
       "      <td>-90.261215</td>\n",
       "      <td>-1.840977</td>\n",
       "      <td>-2.043601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.606747</td>\n",
       "      <td>-2.572817</td>\n",
       "      <td>-32.187927</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>29.615108</td>\n",
       "      <td>-370.771851</td>\n",
       "      <td>-109.175720</td>\n",
       "      <td>-1.826731</td>\n",
       "      <td>-2.023795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.152111</td>\n",
       "      <td>-10.830464</td>\n",
       "      <td>-67.888519</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>57.058060</td>\n",
       "      <td>-727.777832</td>\n",
       "      <td>-191.752182</td>\n",
       "      <td>-1.688231</td>\n",
       "      <td>-1.884434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>2.430600</td>\n",
       "      <td>2.131727</td>\n",
       "      <td>-16.584421</td>\n",
       "      <td>-77.611404</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>61.026981</td>\n",
       "      <td>-825.006653</td>\n",
       "      <td>-249.291763</td>\n",
       "      <td>-1.658810</td>\n",
       "      <td>-1.830627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.110900</td>\n",
       "      <td>0.715735</td>\n",
       "      <td>-9.445674</td>\n",
       "      <td>-61.010994</td>\n",
       "      <td>0.953125</td>\n",
       "      <td>51.565315</td>\n",
       "      <td>-659.002563</td>\n",
       "      <td>-177.904297</td>\n",
       "      <td>-1.755488</td>\n",
       "      <td>-1.949493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>2.477100</td>\n",
       "      <td>0.398090</td>\n",
       "      <td>-3.072147</td>\n",
       "      <td>-35.552959</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>32.480812</td>\n",
       "      <td>-404.422180</td>\n",
       "      <td>-114.169029</td>\n",
       "      <td>-1.851581</td>\n",
       "      <td>-2.032213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.334473</td>\n",
       "      <td>-2.110941</td>\n",
       "      <td>-30.719183</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>28.608240</td>\n",
       "      <td>-356.084412</td>\n",
       "      <td>-104.556961</td>\n",
       "      <td>-1.858294</td>\n",
       "      <td>-2.035376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.365686</td>\n",
       "      <td>-4.672747</td>\n",
       "      <td>-43.122311</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>38.449562</td>\n",
       "      <td>-480.115692</td>\n",
       "      <td>-130.175018</td>\n",
       "      <td>-1.823448</td>\n",
       "      <td>-2.011975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.368736</td>\n",
       "      <td>-5.207455</td>\n",
       "      <td>-45.587906</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>40.380447</td>\n",
       "      <td>-504.771606</td>\n",
       "      <td>-135.522095</td>\n",
       "      <td>-1.796012</td>\n",
       "      <td>-1.990579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.575200</td>\n",
       "      <td>0.321213</td>\n",
       "      <td>-2.917326</td>\n",
       "      <td>-33.315807</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>30.398481</td>\n",
       "      <td>-382.050659</td>\n",
       "      <td>-112.620819</td>\n",
       "      <td>-1.820271</td>\n",
       "      <td>-2.004819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.310990</td>\n",
       "      <td>-1.690132</td>\n",
       "      <td>-26.939924</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>25.249792</td>\n",
       "      <td>-318.291870</td>\n",
       "      <td>-100.348869</td>\n",
       "      <td>-1.828967</td>\n",
       "      <td>-2.007025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.348100</td>\n",
       "      <td>0.316586</td>\n",
       "      <td>-1.780206</td>\n",
       "      <td>-28.318958</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>26.538752</td>\n",
       "      <td>-332.082184</td>\n",
       "      <td>-101.249603</td>\n",
       "      <td>-1.829611</td>\n",
       "      <td>-2.017519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.316283</td>\n",
       "      <td>-1.981118</td>\n",
       "      <td>-29.548216</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>27.567097</td>\n",
       "      <td>-344.374756</td>\n",
       "      <td>-103.258728</td>\n",
       "      <td>-1.825146</td>\n",
       "      <td>-2.019074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.314291</td>\n",
       "      <td>-2.262676</td>\n",
       "      <td>-31.051525</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>28.788849</td>\n",
       "      <td>-359.407867</td>\n",
       "      <td>-106.074318</td>\n",
       "      <td>-1.818057</td>\n",
       "      <td>-2.014411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312608</td>\n",
       "      <td>-2.383364</td>\n",
       "      <td>-31.584072</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>29.200710</td>\n",
       "      <td>-364.733337</td>\n",
       "      <td>-107.281181</td>\n",
       "      <td>-1.814932</td>\n",
       "      <td>-2.012352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2144 > 2048). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=250, training_loss=0.5755126342626233, metrics={'train_runtime': 3265.3745, 'train_samples_per_second': 0.153, 'train_steps_per_second': 0.077, 'total_flos': 0.0, 'train_loss': 0.5755126342626233, 'epoch': 2.16})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dpo_trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dbc5a96-0c6e-4b2e-a441-b2a9367ed0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '/home/jovyan/sai/biomedgpt_dpo7b'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacf2ce2-2711-4e3c-a303-11bb0e913475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff53720-eaba-4857-b706-38ab2109977a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpo_trainer.save_model(\"biomedgpt_dpo7b\")\n",
    "output_dir = os.path.join(\"biomedgpt_dpo7b\", \"final_checkpoint\")\n",
    "dpo_trainer.model.save_pretrained(output_dir)\n",
    "\n",
    "# Free memory for merging weights\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#model = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\", torch_dtype=torch.float16)\n",
    "#model = model.merge_and_unload()\n",
    "\n",
    "#output_merged_dir = os.path.join(\"biomedgpt_dpo7b\", \"final_merged_checkpoint\")\n",
    "#model.save_pretrained(output_merged_dir, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34dca693-7503-46fc-9241-dabfc2dafd3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01244d4ddba46e484b5a739e18f986f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.conda/envs/ppo/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:362: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "/home/jovyan/.conda/envs/ppo/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:367: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n",
      "/home/jovyan/.conda/envs/ppo/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:508: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n",
      "\n",
      "Thrown during validation:\n",
      "`do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"PharMolix/BioMedGPT-LM-7B\", trust_remote_code=True,device_map=\"auto\", torch_dtype=torch.float16)\n",
    "model = PeftModel.from_pretrained(model, \"/home/jovyan/sai/biomedgpt_dpo7b\")\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "output_merged_dir = os.path.join(\"biomedgpt_dpo7b\", \"final_merged_checkpoint\")\n",
    "model.save_pretrained(output_merged_dir, safe_serialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650dacd9-4326-4bf1-b5e0-6f80e9f040cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
