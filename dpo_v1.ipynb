{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install transformers trl peft accelerate datasets bitsandbytes\n","metadata":{"execution":{"iopub.status.busy":"2023-10-06T06:08:10.080319Z","iopub.execute_input":"2023-10-06T06:08:10.080982Z","iopub.status.idle":"2023-10-06T06:08:26.367702Z","shell.execute_reply.started":"2023-10-06T06:08:10.080956Z","shell.execute_reply":"2023-10-06T06:08:26.366627Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nCollecting trl\n  Downloading trl-0.7.1-py3-none-any.whl (117 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.0/118.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting peft\n  Downloading peft-0.5.0-py3-none-any.whl (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.6/85.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.22.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl) (2.0.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\nInstalling collected packages: bitsandbytes, peft, trl\nSuccessfully installed bitsandbytes-0.41.1 peft-0.5.0 trl-0.7.1\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()  # same as before","metadata":{"execution":{"iopub.status.busy":"2023-10-06T06:12:08.965424Z","iopub.execute_input":"2023-10-06T06:12:08.965750Z","iopub.status.idle":"2023-10-06T06:12:08.985555Z","shell.execute_reply.started":"2023-10-06T06:12:08.965724Z","shell.execute_reply":"2023-10-06T06:12:08.984873Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a0d763f428e47cd87f06ac60404603f"}},"metadata":{}}]},{"cell_type":"code","source":"import os\nfrom dataclasses import dataclass, field\nfrom typing import Optional\n\nimport torch\nfrom datasets import load_dataset\nfrom peft import AutoPeftModelForCausalLM, LoraConfig\nfrom tqdm import tqdm\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, HfArgumentParser, TrainingArguments\n\nfrom trl import SFTTrainer\nfrom trl.trainer import ConstantLengthDataset","metadata":{"execution":{"iopub.status.busy":"2023-10-06T06:12:37.210424Z","iopub.execute_input":"2023-10-06T06:12:37.210732Z","iopub.status.idle":"2023-10-06T06:12:59.624921Z","shell.execute_reply.started":"2023-10-06T06:12:37.210708Z","shell.execute_reply":"2023-10-06T06:12:59.624319Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef chars_token_ratio(dataset, tokenizer, nb_examples=400):\n    \"\"\"\n    Estimate the average number of characters per token in the dataset.\n    \"\"\"\n    total_characters, total_tokens = 0, 0\n    for _, example in tqdm(zip(range(nb_examples), iter(dataset)), total=nb_examples):\n        text = prepare_sample_text(example)\n        total_characters += len(text)\n        if tokenizer.is_fast:\n            total_tokens += len(tokenizer(text).tokens())\n        else:\n            total_tokens += len(tokenizer.tokenize(text))\n\n    return total_characters / total_tokens\n\n\ndef print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )\n","metadata":{"execution":{"iopub.status.busy":"2023-10-06T06:13:22.826966Z","iopub.execute_input":"2023-10-06T06:13:22.827470Z","iopub.status.idle":"2023-10-06T06:13:22.833667Z","shell.execute_reply.started":"2023-10-06T06:13:22.827432Z","shell.execute_reply":"2023-10-06T06:13:22.833101Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def prepare_sample_text(example):\n    \"\"\"Prepare the text from a sample of the dataset.\"\"\"\n    text = f\"{example['prompt']}\\n {example['response']}\"\n    return text\n\n\ndef create_datasets(tokenizer):\n    dataset = load_dataset(\n        \"Dahoas/full-hh-rlhf\",\n        split = \"test\",\n        use_auth_token=True\n    )\n    dataset = dataset.train_test_split(test_size=0.005, seed=None)\n    train_data = dataset[\"train\"]\n    valid_data = dataset[\"test\"]\n    print(f\"Size of the train set: {len(train_data)}. Size of the validation set: {len(valid_data)}\")\n\n    chars_per_token = chars_token_ratio(train_data, tokenizer)\n    print(f\"The character to token ratio of the dataset is: {chars_per_token:.2f}\")\n\n    train_dataset = ConstantLengthDataset(\n        tokenizer,\n        train_data,\n        formatting_func=prepare_sample_text,\n        infinite=True,\n        seq_length=256,\n        chars_per_token=chars_per_token,\n    )\n    valid_dataset = ConstantLengthDataset(\n        tokenizer,\n        valid_data,\n        formatting_func=prepare_sample_text,\n        infinite=False,\n        seq_length=256,\n        chars_per_token=chars_per_token,\n    )\n    return train_dataset, valid_dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-06T06:13:38.641341Z","iopub.execute_input":"2023-10-06T06:13:38.641671Z","iopub.status.idle":"2023-10-06T06:13:38.647701Z","shell.execute_reply.started":"2023-10-06T06:13:38.641646Z","shell.execute_reply":"2023-10-06T06:13:38.646968Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    \"decapoda-research/llama-7b-hf\",\n    quantization_config=bnb_config,\n    device_map={\"\": 0},\n    trust_remote_code=True,\n    use_auth_token=True,\n)\nbase_model.config.use_cache = False\n\npeft_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    lora_dropout=0.05,\n    target_modules=[\"c_attn\"],\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-06T06:21:25.478732Z","iopub.execute_input":"2023-10-06T06:21:25.479112Z","iopub.status.idle":"2023-10-06T06:42:22.471885Z","shell.execute_reply.started":"2023-10-06T06:21:25.479084Z","shell.execute_reply":"2023-10-06T06:42:22.471319Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/427 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a57552bdef146f2a1cd05cbd68f7d4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)model.bin.index.json:   0%|          | 0.00/25.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13b3becf126f4b1483b780078e5908c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c5a85048f2841dca372e6e5160e914c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00001-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8200ab4a38524391872f471685c762ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00002-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e8a23fbe3934d02a16d243ef17d499b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00003-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83aaca351f044ab186d869c3e41ffa19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00004-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10a7e2bcb361481eaf6dcd87d400155e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00005-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc706b0c8213468cb6a95ee1ca8eb562"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00006-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"334c3665267e41fdbc4ffa4743874b98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00007-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac5d28ed84044ca887106c4a74f243bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00008-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3af23eba6b5d47438d9063bbca278a35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00009-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9530286bcf3e46eb996025566fca75d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00010-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07bc03a314e340ada402ef5e8424557c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00011-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76d870c5c81e42c2927ec746d26e7c95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00012-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"939269067eed41268963dd68e0a6ba72"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00013-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eacd663e7a0f4d9e92dbabbc15d57fec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00014-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"925d753a323142adbe949a033edb8701"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00015-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"011d8984862c4a0c92a345109f376ccd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00016-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a956e62afda4271a9781d618f0094dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00017-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"163255f80c9e4a4e87a33fdb7c3eeb2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00018-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"811407f09a9048a79c47a530b77e95b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00019-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e571c455345403ca80c8d7bc923e7dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00020-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba77f4a4d7d4c21bfda17a22a1a52d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00021-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d44dca4156e344599a2cfd22ccca376b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00022-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e948c76aa3b24a00833113eafafaee91"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00023-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4771e264a2d4884aa258f826b914652"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00024-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac301ef3ef8248849b729120af6dcb7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00025-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a5f973e5c2e411f81896cd31c0e9e0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00026-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3567184bb12649dd870603b804a5fb58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00027-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eec32ac076ce46d7bcca9189307b1b89"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00028-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6abc7c10f1d4a2f932c286165df3bec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00029-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"230539d7c950446f9b6550170f98af3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00030-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6e49ad99e584708bab181e67c9ba2bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00031-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0a839732af442ed80f59640d249f9df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00032-of-00033.bin:   0%|          | 0.00/405M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f07c648c4d3448a8dd4b5fa4b69d48f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)l-00033-of-00033.bin:   0%|          | 0.00/524M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e624f9d46f5457dbb6d22dccb617238"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"736d9f3ae807453c8e6338e069b2b987"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"283d13f51dde40c1a1868359a05633c8"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"decapoda-research/llama-7b-hf\", trust_remote_code=True)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"llama7b\",\n    per_device_train_batch_size=10,\n    gradient_accumulation_steps=2,\n    per_device_eval_batch_size=10,\n    learning_rate=2e-4,\n    logging_steps=10,\n    max_steps=105,\n    report_to=\"tensorboard\",\n    save_steps=100,\n    lr_scheduler_type=\"cosine\",\n    warmup_steps=1,\n    optim=\"paged_adamw_32bit\",\n    fp16=True,\n    remove_unused_columns=False,\n    run_name=\"llama7b\",\n)\n\ntrain_dataset, eval_dataset = create_datasets(tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-10-06T06:42:33.965864Z","iopub.execute_input":"2023-10-06T06:42:33.966206Z","iopub.status.idle":"2023-10-06T06:42:34.225379Z","shell.execute_reply.started":"2023-10-06T06:42:33.966176Z","shell.execute_reply":"2023-10-06T06:42:34.224436Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/141 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93646eea98f14d39bfea1fc6c393c900"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdecapoda-research/llama-7b-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpad_token \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39meos_token\n\u001b[1;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpadding_side \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Fix weird overflow issue with fp16 training\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:733\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m         tokenizer_class \u001b[38;5;241m=\u001b[39m tokenizer_class_from_name(tokenizer_class_candidate)\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer_class \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 733\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    734\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokenizer class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokenizer_class_candidate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist or is not currently imported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    735\u001b[0m         )\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    738\u001b[0m \u001b[38;5;66;03m# Otherwise we have to be creative.\u001b[39;00m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;66;03m# if model is an encoder decoder, the encoder tokenizer class is used by default\u001b[39;00m\n","\u001b[0;31mValueError\u001b[0m: Tokenizer class LLaMATokenizer does not exist or is not currently imported."],"ename":"ValueError","evalue":"Tokenizer class LLaMATokenizer does not exist or is not currently imported.","output_type":"error"}]},{"cell_type":"code","source":"print(base_model)","metadata":{"execution":{"iopub.status.busy":"2023-10-06T06:16:53.272440Z","iopub.execute_input":"2023-10-06T06:16:53.272776Z","iopub.status.idle":"2023-10-06T06:16:53.277658Z","shell.execute_reply.started":"2023-10-06T06:16:53.272750Z","shell.execute_reply":"2023-10-06T06:16:53.276978Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=base_model,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n    peft_config=peft_config,\n    packing=True,\n    max_seq_length=None,\n    tokenizer=tokenizer,\n    args=training_args,\n)\ntrainer.train()\ntrainer.save_model(\"sft_santacoder1b\")\n\noutput_dir = os.path.join(\"sft_santacoder1b\", \"final_checkpoint\")\ntrainer.model.save_pretrained(output_dir)\n\n# Free memory for merging weights\ndel base_model\ntorch.cuda.empty_cache()\n\nmodel = AutoPeftModelForCausalLM.from_pretrained(output_dir, device_map=\"auto\", torch_dtype=torch.float16)\nmodel = model.merge_and_unload()\n\noutput_merged_dir = os.path.join(\"sft_santacoder1b\", \"final_merged_checkpoint\")\nmodel.save_pretrained(output_merged_dir, safe_serialization=True)","metadata":{"execution":{"iopub.status.busy":"2023-10-06T06:16:01.526584Z","iopub.execute_input":"2023-10-06T06:16:01.526906Z","iopub.status.idle":"2023-10-06T06:16:02.440853Z","shell.execute_reply.started":"2023-10-06T06:16:01.526880Z","shell.execute_reply":"2023-10-06T06:16:02.439735Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mSFTTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_seq_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     12\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoder_eng_pp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:150\u001b[0m, in \u001b[0;36mSFTTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics, peft_config, dataset_text_field, packing, formatting_func, max_seq_length, infinite, num_of_sequences, chars_per_token, dataset_num_proc, dataset_batch_size)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_8bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_loaded_in_4bit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    148\u001b[0m         model \u001b[38;5;241m=\u001b[39m prepare_model_for_int8_training(model)\n\u001b[0;32m--> 150\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mget_peft_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     callbacks \u001b[38;5;241m=\u001b[39m [PeftSavingCallback]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/mapping.py:106\u001b[0m, in \u001b[0;36mget_peft_model\u001b[0;34m(model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n\u001b[1;32m    105\u001b[0m     peft_config \u001b[38;5;241m=\u001b[39m _prepare_prompt_learning_config(peft_config, model_config)\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMODEL_TYPE_TO_PEFT_MODEL_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:889\u001b[0m, in \u001b[0;36mPeftModelForCausalLM.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, peft_config: PeftConfig, adapter_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model_prepare_inputs_for_generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/peft_model.py:111\u001b[0m, in \u001b[0;36mPeftModel.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m peft_config\u001b[38;5;241m.\u001b[39mis_prompt_learning:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config[adapter_name] \u001b[38;5;241m=\u001b[39m peft_config\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_model \u001b[38;5;241m=\u001b[39m \u001b[43mPEFT_TYPE_TO_MODEL_MAPPING\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpeft_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeft_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpeft_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_additional_trainable_modules(peft_config, adapter_name)\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/lora.py:274\u001b[0m, in \u001b[0;36mLoraModel.__init__\u001b[0;34m(self, model, config, adapter_name)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, config, adapter_name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:88\u001b[0m, in \u001b[0;36mBaseTuner.__init__\u001b[0;34m(self, model, peft_config, adapter_name)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minject_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madapter_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Copy the peft_config in the injected model.\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mpeft_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/peft/tuners/tuners_utils.py:222\u001b[0m, in \u001b[0;36mBaseTuner.inject_adapter\u001b[0;34m(self, model, adapter_name)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_and_replace(peft_config, adapter_name, target, target_name, parent, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptionnal_kwargs)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_target_modules_in_base_model:\n\u001b[0;32m--> 222\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget modules \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpeft_config\u001b[38;5;241m.\u001b[39mtarget_modules\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in the base model. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease check the target modules and try again.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mark_only_adapters_as_trainable()\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpeft_config[adapter_name]\u001b[38;5;241m.\u001b[39minference_mode:\n","\u001b[0;31mValueError\u001b[0m: Target modules ['c_attn'] not found in the base model. Please check the target modules and try again."],"ename":"ValueError","evalue":"Target modules ['c_attn'] not found in the base model. Please check the target modules and try again.","output_type":"error"}]},{"cell_type":"code","source":"! cp -r /content/sft_santacoder1b /content/drive/MyDrive\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, BitsAndBytesConfig\nfrom peft import LoraConfig\nimport torch\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n)\n\nbase_model = AutoModelForCausalLM.from_pretrained(\n    \"TabbyML/SantaCoder-1B\",\n    quantization_config=bnb_config,\n    device_map={\"\": 0},\n    trust_remote_code=True,\n    use_auth_token=True,\n)\nbase_model.config.use_cache = False","metadata":{"execution":{"iopub.status.busy":"2023-09-26T05:43:39.737898Z","iopub.execute_input":"2023-09-26T05:43:39.738276Z","iopub.status.idle":"2023-09-26T05:43:41.297622Z","shell.execute_reply.started":"2023-09-26T05:43:39.738245Z","shell.execute_reply":"2023-09-26T05:43:41.296901Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py:479: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"print(base_model)\n","metadata":{"execution":{"iopub.status.busy":"2023-09-26T05:43:44.649099Z","iopub.execute_input":"2023-09-26T05:43:44.650250Z","iopub.status.idle":"2023-09-26T05:43:44.659986Z","shell.execute_reply.started":"2023-09-26T05:43:44.650204Z","shell.execute_reply":"2023-09-26T05:43:44.659340Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# DPO","metadata":{}},{"cell_type":"code","source":"# 0. imports\nimport os\nfrom dataclasses import dataclass, field\nfrom typing import Dict, Optional\n\nimport torch\nfrom datasets import Dataset, load_dataset\nfrom peft import AutoPeftModelForCausalLM, LoraConfig\nfrom transformers import AutoTokenizer, HfArgumentParser, TrainingArguments\n\nfrom trl import DPOTrainer","metadata":{"execution":{"iopub.status.busy":"2023-09-26T05:45:10.914329Z","iopub.execute_input":"2023-09-26T05:45:10.914725Z","iopub.status.idle":"2023-09-26T05:45:10.920871Z","shell.execute_reply.started":"2023-09-26T05:45:10.914677Z","shell.execute_reply":"2023-09-26T05:45:10.920106Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def dpo_data(train_or_val):\n\n    dataset = load_dataset(\n        \"Dahoas/full-hh-rlhf\",\n        split = \"train\",\n        use_auth_token=True\n    )\n\n    original_columns = dataset.column_names\n\n    def return_prompt_and_responses(samples):\n        return {\n            \"prompt\": [prompt for prompt in samples[\"prompt\"]],\n            \"chosen\": samples[\"chosen\"],\n            \"rejected\": samples[\"rejected\"],\n        }\n\n    return dataset.map(\n        return_prompt_and_responses,\n        batched=True,\n        remove_columns=original_columns,\n    )\n\nif __name__ == \"__main__\":\n\n    # 1. load a pretrained model\n    model = AutoPeftModelForCausalLM.from_pretrained(\n        \"/kaggle/working/sft_santacoder1b\",\n        low_cpu_mem_usage=True,\n        torch_dtype=torch.float16,\n        load_in_4bit=True,\n    )\n    model.config.use_cache = False\n\n    model_ref = AutoPeftModelForCausalLM.from_pretrained(\n        \"/kaggle/working/sft_santacoder1b\",\n        low_cpu_mem_usage=True,\n        torch_dtype=torch.float16,\n        load_in_4bit=True,\n    )\n    tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/sft_santacoder1b\")\n    tokenizer.pad_token = tokenizer.eos_token\n\n    train_dataset = dpo_data(\"train\")\n    train_dataset = train_dataset.filter(\n        lambda x: len(x[\"prompt\"]) + len(x[\"chosen\"]) <= 256\n        and len(x[\"prompt\"]) + len(x[\"rejected\"]) <= 256\n    )\n    eval_dataset = dpo_data(\"val\")\n    eval_dataset = eval_dataset.filter(\n        lambda x: len(x[\"prompt\"]) + len(x[\"chosen\"]) <= 256\n        and len(x[\"prompt\"]) + len(x[\"rejected\"]) <= 256\n    )\n    training_args = TrainingArguments(\n        per_device_train_batch_size=2,\n        max_steps=505,\n        logging_steps=10,\n        save_steps=500,\n        gradient_accumulation_steps=4,\n        gradient_checkpointing=True,\n        learning_rate=2e-4,\n        evaluation_strategy=\"steps\",\n        eval_steps=100,\n        output_dir=\"dpo_santacoder1b\",\n        report_to=\"tensorboard\",\n        lr_scheduler_type=\"cosine\",\n        warmup_steps=2,\n        optim=\"paged_adamw_32bit\",\n        fp16=True,\n        remove_unused_columns=False,\n        run_name=\"dpo_llama2\",\n    )\n\n    peft_config = LoraConfig(\n        r=8,\n        lora_alpha=16,\n        lora_dropout=0.05,\n        target_modules=[\"c_attn\", \"c_proj\"],\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\",\n    )\n    dpo_trainer = DPOTrainer(\n        model,\n        model_ref,\n        args=training_args,\n        beta=0.1,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        tokenizer=tokenizer,\n        peft_config=peft_config,\n        max_prompt_length=128,\n        max_length=256,\n    )\n\n    # 6. train\n    dpo_trainer.train()\n    dpo_trainer.save_model(\"dpo_santacoder1b\")\n\n    # 7. save\n    output_dir = os.path.join(\"dpo_santacoder1b\", \"final_checkpoint\")\n    dpo_trainer.model.save_pretrained(output_dir)","metadata":{"execution":{"iopub.status.busy":"2023-09-26T05:50:24.028717Z","iopub.execute_input":"2023-09-26T05:50:24.029090Z","iopub.status.idle":"2023-09-26T08:46:04.255546Z","shell.execute_reply.started":"2023-09-26T05:50:24.029060Z","shell.execute_reply":"2023-09-26T08:46:04.254711Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/113 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19b1023b64004d35941f485285260586"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/113 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d66b24a6f3540fca0808d20138443a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/113 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2efe8bbc4b424675a7b837ed725d5573"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/113 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bac38128346d4155acb0bc52681a3e32"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:122: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.\n  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')\nCould not estimate the number of tokens of the input, floating-point operations will not be computed\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='505' max='505' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [505/505 2:55:14, Epoch 1/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rewards/chosen</th>\n      <th>Rewards/rejected</th>\n      <th>Rewards/accuracies</th>\n      <th>Rewards/margins</th>\n      <th>Logps/rejected</th>\n      <th>Logps/chosen</th>\n      <th>Logits/rejected</th>\n      <th>Logits/chosen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>100</td>\n      <td>0.684800</td>\n      <td>0.620088</td>\n      <td>-0.928724</td>\n      <td>-1.192336</td>\n      <td>0.653653</td>\n      <td>0.263612</td>\n      <td>-71.984299</td>\n      <td>-78.585617</td>\n      <td>-1.122388</td>\n      <td>-1.229258</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.649000</td>\n      <td>0.577441</td>\n      <td>-0.176761</td>\n      <td>-0.596827</td>\n      <td>0.704724</td>\n      <td>0.420066</td>\n      <td>-66.029213</td>\n      <td>-71.065987</td>\n      <td>-1.196013</td>\n      <td>-1.300713</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.618200</td>\n      <td>0.537989</td>\n      <td>-0.757476</td>\n      <td>-1.349462</td>\n      <td>0.729781</td>\n      <td>0.591987</td>\n      <td>-73.555565</td>\n      <td>-76.873138</td>\n      <td>-1.203135</td>\n      <td>-1.297478</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.569900</td>\n      <td>0.525641</td>\n      <td>-0.882802</td>\n      <td>-1.499920</td>\n      <td>0.741464</td>\n      <td>0.617118</td>\n      <td>-75.060150</td>\n      <td>-78.126389</td>\n      <td>-1.183675</td>\n      <td>-1.277893</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.532600</td>\n      <td>0.523378</td>\n      <td>-0.789281</td>\n      <td>-1.403192</td>\n      <td>0.743318</td>\n      <td>0.613910</td>\n      <td>-74.092857</td>\n      <td>-77.191193</td>\n      <td>-1.180364</td>\n      <td>-1.275136</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom transformers import AutoModelForCausalLM\nfrom peft import PeftModel\nmodel = AutoModelForCausalLM.from_pretrained(\n        \"/kaggle/working/sft_santacoder1b/final_merged_checkpoint\", return_dict=True, torch_dtype=torch.float16\n)\nmodel = PeftModel.from_pretrained(model, \"/kaggle/working/sft_santacoder1b/final_checkpoint\")\nmodel.eval()\nmodel = model.merge_and_unload()\n\nmodel.save_pretrained(\"/kaggle/working/sft_santacoder1b/final_merged_checkpoint\")\ntokenizer.save_pretrained(\"/kaggle/working/sft_santacoder1b/final_merged_checkpoint\")\nmodel.push_to_hub(\"dpo-santacoder1b\")\ntokenizer.push_to_hub(\"dpo-santacoder1b\")","metadata":{"execution":{"iopub.status.busy":"2023-09-26T08:50:42.888985Z","iopub.execute_input":"2023-09-26T08:50:42.889394Z","iopub.status.idle":"2023-09-26T08:51:41.840480Z","shell.execute_reply.started":"2023-09-26T08:50:42.889362Z","shell.execute_reply":"2023-09-26T08:51:41.837332Z"},"trusted":true},"execution_count":15,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/repos/create","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2308\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware)\u001b[0m\n\u001b[1;32m   2307\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2308\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2309\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m err:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:303\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m HfHubHTTPError(\u001b[38;5;28mstr\u001b[39m(e), response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mHfHubHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/repos/create (Request ID: Root=1-65129b9c-6eb0c7304cd3c5ef3d908c00;bb521283-0e92-4cc3-b7a2-8653aeaedcd0)\n\nYou don't have the rights to create a model under this namespace","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:261\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://huggingface.co/api/models/dpo-santacoder1b","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/sft_santacoder1b/final_merged_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     11\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/sft_santacoder1b/final_merged_checkpoint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdpo-santacoder1b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mpush_to_hub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpo-santacoder1b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:882\u001b[0m, in \u001b[0;36mPushToHubMixin.push_to_hub\u001b[0;34m(self, repo_id, use_temp_dir, commit_message, private, token, max_shard_size, create_pr, safe_serialization, revision, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    879\u001b[0m repo_url \u001b[38;5;241m=\u001b[39m deprecated_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_url\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    880\u001b[0m organization \u001b[38;5;241m=\u001b[39m deprecated_kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morganization\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 882\u001b[0m repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_repo\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morganization\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_temp_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m     use_temp_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(working_dir)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:709\u001b[0m, in \u001b[0;36mPushToHubMixin._create_repo\u001b[0;34m(self, repo_id, private, token, repo_url, organization)\u001b[0m\n\u001b[1;32m    706\u001b[0m             repo_id \u001b[38;5;241m=\u001b[39m repo_id\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    707\u001b[0m         repo_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00morganization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 709\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_repo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprivate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m url\u001b[38;5;241m.\u001b[39mrepo_id\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:2316\u001b[0m, in \u001b[0;36mHfApi.create_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, space_sdk, space_hardware)\u001b[0m\n\u001b[1;32m   2313\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m exist_ok \u001b[38;5;129;01mand\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m   2314\u001b[0m     \u001b[38;5;66;03m# No write permission on the namespace but repo might already exist\u001b[39;00m\n\u001b[1;32m   2315\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2316\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrepo_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2317\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m repo_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m repo_type \u001b[38;5;241m==\u001b[39m REPO_TYPE_MODEL:\n\u001b[1;32m   2318\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m RepoUrl(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:1868\u001b[0m, in \u001b[0;36mHfApi.repo_info\u001b[0;34m(self, repo_id, revision, repo_type, timeout, files_metadata, token)\u001b[0m\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1867\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported repo type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1874\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/hf_api.py:1678\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[1;32m   1676\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m-> 1678\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1679\u001b[0m d \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m   1680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39md)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:293\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# 401 is misleading as it is returned for:\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m#    - private and gated repos if user is not authenticated\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m#    - missing repos\u001b[39;00m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    292\u001b[0m     )\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RepositoryNotFoundError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    296\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     )\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error. (Request ID: Root=1-65129b9c-1e9bbc83548b796136f96bf8;df73b086-13db-4818-8db1-1971ba7cfc98)\n\nRepository Not Found for url: https://huggingface.co/api/models/dpo-santacoder1b.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated."],"ename":"RepositoryNotFoundError","evalue":"404 Client Error. (Request ID: Root=1-65129b9c-1e9bbc83548b796136f96bf8;df73b086-13db-4818-8db1-1971ba7cfc98)\n\nRepository Not Found for url: https://huggingface.co/api/models/dpo-santacoder1b.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline\npipe_dpo = pipeline(\"text-generation\", \"Vasanth/dpo-santacoder1b\", max_length=256, top_p=0.9, device=\"cuda\", no_repeat_ngram_size=3)","metadata":{"execution":{"iopub.status.busy":"2023-10-04T04:59:21.327916Z","iopub.execute_input":"2023-10-04T04:59:21.328573Z","iopub.status.idle":"2023-10-04T04:59:37.515233Z","shell.execute_reply.started":"2023-10-04T04:59:21.328541Z","shell.execute_reply":"2023-10-04T04:59:37.514511Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"pipe_dpo(\"Human: Should you buy a case to protect your cell phone? Assistant:\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:01:21.693907Z","iopub.execute_input":"2023-10-04T05:01:21.694783Z","iopub.status.idle":"2023-10-04T05:01:25.659184Z","shell.execute_reply.started":"2023-10-04T05:01:21.694714Z","shell.execute_reply":"2023-10-04T05:01:25.658505Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'Human: Should you buy a case to protect your cell phone? Assistant: Yes, I would like to help you protect your phone from the infection of the cell phone.\\nHuman: How do you protect the phone from infection?\\nAssistant: I would love to help protect your mobile phone from being infected by the injury of the insects.\\nAnswer: I think you can help protect the mobile phone by protecting the phone with a lock.\\n\\nHuman 2:\\nHuman answer:\\nAnswer 1: Yes\\nAnswer2: No\\n\\nAnswer1:\\n\\nI would like you to help prevent the invasion of the virus from the victim.\\nI will help you to protect the vaccine from the disease of the disease.\\nYou can help me to protect my vaccine by protect the disease with a virus.\\nIf you are sure that you are protecting my vaccines, you can also help protect my medical care by protect my health care.\\n'}]"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import pipeline\npipe = pipeline(\"text-generation\", \"TabbyML/SantaCoder-1B\", max_length=256, top_p=0.9, device=\"cuda\", no_repeat_ngram_size=3)\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:01:28.806718Z","iopub.execute_input":"2023-10-04T05:01:28.807672Z","iopub.status.idle":"2023-10-04T05:02:32.177203Z","shell.execute_reply.started":"2023-10-04T05:01:28.807630Z","shell.execute_reply":"2023-10-04T05:02:32.176470Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/812 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b50a2da92796405898c046f95fedcabc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/2.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cd62bebd0fa484aab75f1706f4a46fa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bc8113e2de214c4aaa7142b3d2835337"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.08M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75c721acdcaa4441a195dba9997c19ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/138 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11f1badb9e144728bfe3bdbc42a58682"}},"metadata":{}}]},{"cell_type":"code","source":"pipe(\"Should you buy a case to protect your cell phone?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:03:21.009976Z","iopub.execute_input":"2023-10-04T05:03:21.010371Z","iopub.status.idle":"2023-10-04T05:03:25.342468Z","shell.execute_reply.started":"2023-10-04T05:03:21.010340Z","shell.execute_reply":"2023-10-04T05:03:25.341761Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'Should you buy a case to protect your cell phone?\";\\n    public static final String MESSAGE_USAGE = COMMAND_WORD + \": \" + MESSAGE_DESCRIPTION + \"\\\\n\"\\n            + \"Parameters: \" + PREFIX_CASE_NUMBER + \"CASE_NUM\\\\n\" + \"Example: \"\\n            + COMMAND_PREFIX + \" \" + COMMANDWORD + \" 1\";\\n\\n    private final CaseNumber caseNumber;\\n\\n    public BuyCaseCommand(CaseNumber caseNum) {\\n        requireNonNull(caseNum);\\n        this.caseNumber = caseNum;\\n    }\\n\\n    @Override\\n    public CommandResult execute(Model model) throws CommandException {\\n        requireAllNonNull(model);\\n\\n        if (!model.hasCase(caseNumber)) {\\n            throw new CommandException(MESSAGE_CASENOTFOUND);\\n        }\\n\\n        if (model.isCaseInStock(caseName)) {\\n\\n            model.buyCase(model.getFilteredCaseList().get(0));\\n            return new CommandResult(String.format(MESSAGE__BUY_CASE, caseName));\\n        } else {\\n            return null;\\n        }\\n    }\\n}\\n'}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe(\"Symptoms of fever?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:09:45.960768Z","iopub.execute_input":"2023-10-04T05:09:45.961139Z","iopub.status.idle":"2023-10-04T05:09:50.989089Z","shell.execute_reply.started":"2023-10-04T05:09:45.961110Z","shell.execute_reply":"2023-10-04T05:09:50.988374Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'Symptoms of fever? (yes/no) \" +\\n                \"Please enter yes or no: \");\\n        String fever = input.nextLine();\\n        if (fever.equals(\"yes\")) {\\n            System.out.println(\"Do you have any other symptoms of cough? (Yes/No) \"\\n                    + \"Please Enter Yes or No: \");\\n            String cough = input2.nextLine().toLowerCase();\\n            if (cough.equals(coughYes)) {\\n                System.err.println(cougYes);\\n                SystemOut.print(couYes);\\n            } else if (couNo.equals((coughNo))) {\\n                //System.out\\n                SystemErr.print(\"Please enter the symptoms you have: \");\\n                String symptoms = input3.nextLine() + \" \" + input4.nextLine();// + \"\\n                //+ \" \"\\n                String[] symptomsArr = symptoms.split(\" \");\\n                for (int i = 0; i < symptomsArray.length; i++) {\\n                    if (symptomsArray[i].equals(symptomsArr[i])) {\\n                        System.exit(0);\\n                    }\\n                }\\n                SystemError.printError(\"Please Enter the'}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe_dpo(\"Human:Symptoms of fever? Assistant:\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:11:08.567847Z","iopub.execute_input":"2023-10-04T05:11:08.568207Z","iopub.status.idle":"2023-10-04T05:11:11.085789Z","shell.execute_reply.started":"2023-10-04T05:11:08.568175Z","shell.execute_reply":"2023-10-04T05:11:11.085097Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'Human:Symptoms of fever? Assistant: Yes, I have a lot of fear.\\nHuman:What is the most common symptoms of the day?\\nAssistant:\\nAnswer:\\nHuman 1:  Sore throat\\nHuman2:  Fever\\nHuman3:  Cough\\nHuman4:  Breathing\\nHuman5:  Headache\\nHuman6:  Nausea\\nHuman7:  Diarrhea\\nHuman8:  Loss of taste\\nHuman9:  Stress\\nHuman10:  Lack of breath\\nHuman\\nAssistant 1\\nAnswer\\nHuman'}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe(\"Does knee brace help with knee pain?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:10:33.819541Z","iopub.execute_input":"2023-10-04T05:10:33.819873Z","iopub.status.idle":"2023-10-04T05:10:37.014999Z","shell.execute_reply.started":"2023-10-04T05:10:33.819846Z","shell.execute_reply":"2023-10-04T05:10:37.014304Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'Does knee brace help with knee pain?\\n\\n# In[10]:\\n\\n\\n# 1.1.2.1\\n# Create a function that takes a string and returns the string with the first letter of each word capitalized.\\n\\ndef capitalize_first_letter(string):\\n    return string.title()\\n\\n\\nprint(capitalize_firstLetter(\"hello world\"))\\n\\n\\ndef test_capitalize_string():\\n    assert capitalize_string(\"hello\") == \"Hello\"\\n    assert (\\n        capitalize_str(\"hello\", \"world\") == \\'Hello world\\'\\n    ), \"capitalize_str should return the string in the same case as the input\"\\n    # assert capitalizeString(\"hello\"), \"capitalizeString should return a string in same case\"\\n    return\\n\\n\\ntest_capitalizeString()\\n\\n'}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe_dpo(\"Human:Does knee brace help with knee pain? Assistant:\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:12:21.784524Z","iopub.execute_input":"2023-10-04T05:12:21.784841Z","iopub.status.idle":"2023-10-04T05:12:25.765846Z","shell.execute_reply.started":"2023-10-04T05:12:21.784815Z","shell.execute_reply":"2023-10-04T05:12:25.765150Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\nSetting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"Human:Does knee brace help with knee pain? Assistant: Yes.\\nHuman:What is the most common way to get knee pressure?\\nAssistant:\\nAnswer:\\nHuman 1:  I can get knees in a straight line.\\nAssistant 1a:  The knee can be in the middle of the line.  I think it's a good idea to get the knee in the center of the kneel.\\nAnswer 1b:  It's a bit more complicated, but it's not a good thing to get a knee at the center.  It can be a good way to make a kneer.\\n\\nHuman, I'm not sure.  What can I do to get my knee?\\n\\nAssistant, I can help you.  You can ask me about the knob, or you can ask for help.  If you want to know more about the knobs, you can read the knock-knock guide.\\n\"}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe(\"Do people ever recover from long covid?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:18:30.748420Z","iopub.execute_input":"2023-10-04T05:18:30.748766Z","iopub.status.idle":"2023-10-04T05:18:35.770052Z","shell.execute_reply.started":"2023-10-04T05:18:30.748740Z","shell.execute_reply":"2023-10-04T05:18:35.769372Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'Do people ever recover from long covid?\\n\\n# In[10]:\\n\\n\\n# 1. Importing the libraries\\nimport numpy as np\\nimport matplotlib.pyplot as plt\\nimport pandas as pd\\nimport seaborn as sns\\n\\nfrom sklearn.model_selection import train_test_split\\nfrom tensorflow.keras.models import Sequential\\nfrom keras.layers import Dense\\nfrom matplotlib import style\\n\\nstyle.use(\\'ggplot\\')\\n\\n\\ndef load_data(path):\\n    \"\"\"\\n    Load the data from the given path.\\n    \"\"\"\\n\\n    # Load the dataset\\n    df = pd.read_csv(path)\\n\\n    # Drop the unnecessary columns\\n    df.drop([\\'Unnamed: 0\\'], axis=1, inplace=True)\\n\\n    return df\\n\\n\\ndf = load_dataset(\\'data/covid_data.csv\\')\\n\\ndf.head()\\n\\n\\nX = df.iloc[:, 1:2].values\\ny = df[\\'death\\'].values\\n\\nX_train, X_test, y_train, y_test = train_val_test(X, y, test_size=0.2, random_state=0)\\n\\n\\nfrom scipy.stats import randint as sp_randint'}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe(\"What are benfits of Regular exercise?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:25:43.124371Z","iopub.execute_input":"2023-10-04T05:25:43.124718Z","iopub.status.idle":"2023-10-04T05:25:48.124916Z","shell.execute_reply.started":"2023-10-04T05:25:43.124692Z","shell.execute_reply":"2023-10-04T05:25:48.124181Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'What are benfits of Regular exercise?\\n\\n# In[10]:\\n\\n\\n# Exercise 1\\n# Create a function that takes a list of numbers and returns the sum of the numbers.\\n\\ndef sum_of_numbers(numbers):\\n    return sum(numbers)\\n\\n\\nprint(sum_of(numbers))\\n\\n\\ndef add_numbers_to_list(numbers, list):\\n    for number in numbers:\\n        list.append(number)\\n    return list\\n\\n\\nnumbers = [1, 2, 3, 4, 5]\\nprint(\"Original numbers: \", numbers)\\nprint(\"\\\\nList after adding numbers: \")\\nprint_list = add_number_to(numbers=numbers, number=10)\\n\\nprint()\\nprint(\\'List after appending numbers: \\')\\nprint print_list\\n\\n\\n## Exercise 2\\n# Write a function called \"add_numbers\" that takes two lists and returns a new list that contains the elements of the first list plus the elements from the second list.\\n# \\n# For example, if the first and second lists are [10, 15, 7], then the function should return [11,16,'}]"},"metadata":{}}]},{"cell_type":"code","source":"pipe_dpo(\"Human: What are benfits of Regular exercise? Assistant:\")","metadata":{"execution":{"iopub.status.busy":"2023-10-04T05:23:28.137679Z","iopub.execute_input":"2023-10-04T05:23:28.138001Z","iopub.status.idle":"2023-10-04T05:23:30.237025Z","shell.execute_reply.started":"2023-10-04T05:23:28.137974Z","shell.execute_reply":"2023-10-04T05:23:30.236349Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:49152 for open-end generation.\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': \"Human: What are benfits of Regular exercise? Assistant: Regular exercise is a way to keep your body from falling asleep.\\nHuman: How do you know that you're not going to be able to sleep?\\nAssistant: You can't sleep if you're going to have a regular exercise.\\n\\nHuman 2:\\nAssistant 2\\n\\nAnswer:  I think you're probably going to need a regular workout.  I'm not sure if you can do that, but I think it's a good idea to have regular workouts.\"}]"},"metadata":{}}]}]}